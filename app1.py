import pandas as pd
import numpy as np
import warnings
from scipy import stats
from scipy.stats import kurtosis, skew
from sklearn.impute import SimpleImputer
import joblib


import pandas as pd
import numpy as np
import joblib
from scipy import stats
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings("ignore")

class Predictor:
    def __init__(self, scaler_path, svc_path):
        self.scaler = joblib.load(scaler_path)
        self.model = joblib.load(svc_path)
        
        # ç‰¹å¾ç»“æ„å®šä¹‰
        self.static_cols = ["äº§å“è´¨é‡æŒ‡æ ‡_Sn%", "æ·»åŠ æ¯”ä¾‹", "ä¸€ç”²%"]
        self.time_series_cols = ["3min", "6min", "9min", "12min", "15min", "18min", "21min", "24min"]
        self.eng_features = ['seq_length', 'max_value', 'mean_value', 'min_value', 'std_value', 'trend', 'range_value', 'autocorr']
        self.expected_columns = self.static_cols + self.eng_features
        self.full_cols = self.static_cols + self.time_series_cols
        
        # åˆå§‹åŒ–éªŒè¯
        self._validate_components()

    def _validate_components(self):
        """æ ¸å¿ƒéªŒè¯æ–¹æ³•"""
        # ================= ç‰¹å¾ç»´åº¦éªŒè¯ =================
        # è·å–æ ‡å‡†åŒ–å™¨å’Œæ¨¡å‹çš„ç‰¹å¾ç»´åº¦
        scaler_features = getattr(self.scaler, "n_features_in_", None)
        model_features = getattr(self.model, "n_features_in_", None)
        
        # è·å–å½“å‰ä»£ç çš„ç‰¹å¾ç»´åº¦
        code_features = len(self.expected_columns)
        
        error_msgs = []
        if scaler_features != code_features:
            error_msgs.append(
                f"æ ‡å‡†åŒ–å™¨ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼ä»£ç : {code_features}ï¼Œæ ‡å‡†åŒ–å™¨: {scaler_features}"
            )
        if model_features and model_features != code_features:
            error_msgs.append(
                f"æ¨¡å‹ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼ä»£ç : {code_features}ï¼Œæ¨¡å‹: {model_features}"
            )
        if error_msgs:
            raise ValueError("\n".join(error_msgs))

        # ================= ç‰¹å¾åç§°éªŒè¯ =================
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¿å­˜äº†åŸå§‹ç‰¹å¾å
        model_feature_names = getattr(self.model, "feature_names_in_", None)
        if model_feature_names is not None:
            # å¯¹æ¯”ç‰¹å¾åç§°å’Œé¡ºåº
            if list(model_feature_names) != self.expected_columns:
                msg = [
                    "ç‰¹å¾åç§°æˆ–é¡ºåºä¸åŒ¹é…ï¼",
                    f"æ¨¡å‹ç‰¹å¾å: {list(model_feature_names)}",
                    f"ä»£ç é¢„æœŸ: {self.expected_columns}"
                ]
                raise ValueError("\n".join(msg))

        # ================= è™šæ‹Ÿæ•°æ®æµ‹è¯• =================
        # ç”Ÿæˆç¬¦åˆå½“å‰ä»£ç ç»´åº¦çš„éšæœºæ•°æ®
        np.random.seed(42)
        dummy_data = np.random.rand(1, code_features)
        
        try:
            dummy_scaled = self.scaler.transform(dummy_data)
            _ = self.model.predict(dummy_scaled)
        except Exception as e:
            raise RuntimeError(
                f"è™šæ‹Ÿæ•°æ®æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é¢„å¤„ç†æµç¨‹ï¼š{str(e)}"
            ) from e

    def _truncate(self, df):
        """æ—¶é—´åºåˆ—æˆªæ–­é€»è¾‘"""
        time_cols = self.time_series_cols
        row = df[time_cols].iloc[0]
        
        # å¯»æ‰¾æœ€åä¸€ä¸ªæœ‰æ•ˆç‚¹
        last_valid_idx = next(
            (idx for idx in reversed(range(len(time_cols))) if not pd.isna(row.iloc[idx])),
            None
        )
        
        # æ‰§è¡Œæˆªæ–­
        if last_valid_idx is not None and last_valid_idx < len(time_cols)-1:
            invalid_cols = time_cols[last_valid_idx+1:]
            df[invalid_cols] = np.nan
            
        return df
    def _get_slope(self, row, col=None):
        # col æ˜¯å¯é€‰çš„ï¼Œå°†è¢«å¿½ç•¥
        x = np.arange(len(row))
        y = row.values
        mask = ~np.isnan(y)
        if sum(mask) >= 2:
            return stats.linregress(x[mask], y[mask])[0]
        return np.nan

    def _calc_autocorr(self, row):
        """è®¡ç®—ä¸€é˜¶è‡ªç›¸å…³ç³»æ•°"""
        values = row.dropna().values
        if len(values) > 1:
            n = len(values)
            mean = np.mean(values)
            numerator = sum((values[:-1] - mean) * (values[1:] - mean))
            denominator = sum((values - mean) ** 2)
            if denominator != 0:
                return numerator / denominator
        return np.nan
    def _extract_time_series_features(self, df):
        # ç§»é™¤å‰å‘å¡«å……ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆåŒ…å«NaNï¼‰
        time_data = df[self.time_series_cols].copy()
        
        return pd.DataFrame({
            'seq_length': time_data.count(axis=1),  # è®¡ç®—éNaNå€¼çš„æ•°é‡
            'max_value': time_data.max(axis=1),
            'mean_value': time_data.mean(axis=1),
            'min_value': time_data.min(axis=1),
            'std_value': time_data.std(axis=1),
            'trend': time_data.apply(self._get_slope, axis=1),
            'range_value': time_data.max(axis=1) - time_data.min(axis=1),
            'autocorr': time_data.apply(self._calc_autocorr, axis=1)
        }, columns=self.eng_features)
    def predict_one(self, sample):
        if len(sample) != len(self.full_cols):
            raise ValueError(f"éœ€è¦{len(self.full_cols)}ä¸ªç‰¹å¾ï¼Œå®é™…{len(sample)}ä¸ªã€‚å®Œæ•´é¡ºåºï¼š{self.full_cols}")
        
        df = pd.DataFrame([sample], columns=self.full_cols)
        df = self._truncate(df)
        
        # å•æ¬¡åˆå¹¶å¹¶å¼ºåˆ¶åˆ—å
        static_features = df[self.static_cols]
        time_features = self._extract_time_series_features(df)
        feature_df = pd.concat([static_features.reset_index(drop=True), 
                             time_features.reset_index(drop=True)], axis=1)
        feature_df.columns = self.expected_columns
        
        # æœ€ç»ˆéªŒè¯
        if list(feature_df.columns) != self.expected_columns:
            raise ValueError(f"åˆ—åä¸åŒ¹é…ï¼\né¢„æœŸï¼š{self.expected_columns}\nå®é™…ï¼š{feature_df.columns.tolist()}")
        
        return self.model.predict(self.scaler.transform(feature_df))[0]


import streamlit as st
import pandas as pd
import numpy as np
import joblib
import base64
import random
from deap import base, creator, tools, algorithms

# è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬base64
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# é¡µé¢é…ç½®
image_path = "å›¾ç‰‡1.png"
icon_base64 = image_to_base64(image_path)
st.set_page_config(
    page_title="é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°",
    layout="wide",
    page_icon=f"data:image/png;base64,{icon_base64}"
)

# é¡µé¢æ ‡é¢˜æ ·å¼
width = 200
height = int(158 * (width / 507))
st.markdown(
    f"""
    <h1 style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{icon_base64}" style="width: {width}px; height: {height}px; margin-right: 15px;" />
        é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°
    </h1>
    """, 
    unsafe_allow_html=True
)

# ä¾§è¾¹æ ä¸»å¯¼èˆª
page = st.sidebar.selectbox(
    "ğŸ”§ ä¸»åŠŸèƒ½é€‰æ‹©",
    ["é¦–é¡µ","æ€§èƒ½é¢„æµ‹", "é…æ–¹å»ºè®®"],
    key="main_nav"
)

# å­åŠŸèƒ½é€‰æ‹©ï¼ˆä»…åœ¨é…æ–¹å»ºè®®æ—¶æ˜¾ç¤ºï¼‰
sub_page = None
if page == "é…æ–¹å»ºè®®":
    sub_page = st.sidebar.selectbox(
        "ğŸ”§ å­åŠŸèƒ½é€‰æ‹©",
        ["é…æ–¹ä¼˜åŒ–", "æ·»åŠ å‰‚æ¨è"],
        key="sub_nav"
    )

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_models():
    loi_data = joblib.load("model_and_scaler_loi.pkl")
    ts_data = joblib.load("model_and_scaler_ts1.pkl")
    return {
        "loi_model": loi_data["model"],
        "loi_scaler": loi_data["scaler"],
        "ts_model": ts_data["model"],
        "ts_scaler": ts_data["scaler"],
        "loi_features": pd.read_excel("trainrg3.xlsx").drop(columns="LOI", errors='ignore').columns.tolist(),
        "ts_features": pd.read_excel("trainrg3TS.xlsx").drop(columns="TS", errors='ignore').columns.tolist(),
    }
models = load_models()

# è·å–å•ä½
def get_unit(fraction_type):
    if fraction_type == "è´¨é‡":
        return "g"
    elif fraction_type == "è´¨é‡åˆ†æ•°":
        return "wt%"
    elif fraction_type == "ä½“ç§¯åˆ†æ•°":
        return "vol%"

# ä¿è¯PPåœ¨é¦–åˆ—
def ensure_pp_first(features):
    if "PP" in features:
        features.remove("PP")
    return ["PP"] + sorted(features)

# é¦–é¡µ
if page == "é¦–é¡µ":
    st.markdown("""
    <div style="text-align: center;">

        <h1 style="color: #4A90E2;">èšåˆç‰©å¤åˆææ–™æ™ºèƒ½å¹³å°</h1>
    </div>
    """, unsafe_allow_html=True)
    
    # æ°´å¹³åˆ†éš”çº¿
    st.markdown("<hr>", unsafe_allow_html=True)
    
    # åŠŸèƒ½æ¦‚è§ˆ - å¡ç‰‡å¼å¸ƒå±€
    st.markdown("""
    ## åŠŸèƒ½æ¦‚è§ˆ
    <div style="display: flex; justify-content: space-between; gap: 20px;">
        <div style="background: #f0f2f6; padding: 20px; border-radius: 10px; flex: 1;">
            <h3>ğŸ“Š æ€§èƒ½é¢„æµ‹</h3>
            <p>é€šè¿‡è¾“å…¥ææ–™é…æ–¹ï¼Œé¢„æµ‹èšåˆç‰©å¤åˆææ–™çš„ LOI å’ŒTS æ€§èƒ½ã€‚</p>
        </div>
        <div style="background: #f0f2f6; padding: 20px; border-radius: 10px; flex: 1;">
            <h3>ğŸ”§ é…æ–¹å»ºè®®</h3>
            <p>æ ¹æ®ç›®æ ‡æ€§èƒ½ï¼Œä¼˜åŒ–ææ–™é…æ–¹ã€‚</p>
        </div>
        <div style="background: #f0f2f6; padding: 20px; border-radius: 10px; flex: 1;">
            <h3>ğŸ§ª æ·»åŠ å‰‚æ¨è</h3>
            <p>æ ¹æ®é»„åº¦å€¼ç­‰æ—¶åºæ•°æ®ï¼Œæ™ºèƒ½æ¨èæœ€ä½³æ·»åŠ å‰‚ã€‚</p>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ°´å¹³åˆ†éš”çº¿
    st.markdown("<hr>", unsafe_allow_html=True)
    
    # å¼•ç”¨éƒ¨åˆ†
    st.markdown("""
    ## å¼•ç”¨
    <div style="background: #f0f2f6; padding: 20px; border-radius: 10px;">
        <p>Ma W, Li L, Zhang Y, Li M, Song N, Ding P. Active learning-based generative design of halogen-free flame-retardant polymeric composites. J Mater Inf 2025;5:[Accept]. <a href="http://dx.doi.org/10.20517/jmi.2025.09 " target="_blank">DOI</a></p>
    </div>
    """, unsafe_allow_html=True)
    
    # æ°´å¹³åˆ†éš”çº¿
    st.markdown("<hr>", unsafe_allow_html=True)
    
    # è‡´è°¢éƒ¨åˆ†
    st.markdown("""
    ## è‡´è°¢
    <div style="background: #f0f2f6; padding: 20px; border-radius: 10px;">
        <p>äº‘å—çœç§‘æŠ€é‡ç‚¹è®¡åˆ’é¡¹ç›®ï¼ˆ202302AB080022ï¼‰</p>
        <p><strong>å¼€å‘è€…ï¼š</strong>ä¸Šæµ·å¤§å­¦åŠŸèƒ½é«˜åˆ†å­å›¢é˜Ÿï¼šé©¬ç»´å®¾ã€æå‡Œã€å¼ ç‘œã€å®‹å¨œã€ä¸é¹</p>
        <p><strong>å®¡æŸ¥ï¼š</strong>ä¸é¹</p>
    </div>
    """, unsafe_allow_html=True)
    
    # åº•éƒ¨æ¸å˜èƒŒæ™¯
    st.markdown("""
    <style>
    .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        background: linear-gradient(90deg, #4A90E2, #6A82FB);
        color: white;
        text-align: center;
        padding: 10px;
    }


# æ€§èƒ½é¢„æµ‹é¡µé¢
elif page == "æ€§èƒ½é¢„æµ‹":
    st.subheader("ğŸ”® æ€§èƒ½é¢„æµ‹ï¼šåŸºäºé…æ–¹é¢„æµ‹LOIå’ŒTS")

    matrix_materials = ["PP", "PA", "PC/ABS", "POM", "PBT", "PVC", "å…¶ä»–"]
    flame_retardants = [
        "AHP", "ammonium octamolybdate", "Al(OH)3", "CFA", "APP", "Pentaerythritol", "DOPO",
        "EPFR-1100NT", "XS-FR-8310", "ZS", "XiuCheng", "ZHS", "ZnB", "antimony oxides",
        "Mg(OH)2", "TCA", "MPP", "PAPP", "å…¶ä»–"
    ]
    additives = [
        "Anti-drip-agent", "wollastonite", "M-2200B", "ZBS-PV-OA", "FP-250S", "silane coupling agent", "antioxidant",
        "SiO2", "å…¶ä»–"
    ]

    fraction_type = st.sidebar.selectbox("é€‰æ‹©è¾“å…¥çš„å•ä½", ["è´¨é‡", "è´¨é‡åˆ†æ•°", "ä½“ç§¯åˆ†æ•°"])

    st.subheader("è¯·é€‰æ‹©é…æ–¹ä¸­çš„åŸºä½“ã€é˜»ç‡ƒå‰‚å’ŒåŠ©å‰‚")
    selected_matrix = st.selectbox("é€‰æ‹©åŸºä½“", matrix_materials, index=0)
    selected_flame_retardants = st.multiselect("é€‰æ‹©é˜»ç‡ƒå‰‚", flame_retardants, default=["ZS"])
    selected_additives = st.multiselect("é€‰æ‹©åŠ©å‰‚", additives, default=["wollastonite"])

    input_values = {}
    unit = get_unit(fraction_type)

    input_values[selected_matrix] = st.number_input(f"é€‰æ‹© {selected_matrix} ({unit})", min_value=0.0, max_value=100.0, value=50.0, step=0.1)

    for fr in selected_flame_retardants:
        input_values[fr] = st.number_input(f"é€‰æ‹© {fr} ({unit})", min_value=0.0, max_value=100.0, value=10.0, step=0.1)

    for ad in selected_additives:
        input_values[ad] = st.number_input(f"é€‰æ‹© {ad} ({unit})", min_value=0.0, max_value=100.0, value=10.0, step=0.1)

    total = sum(input_values.values())
    is_only_pp = all(v == 0 for k, v in input_values.items() if k != "PP")

    with st.expander("âœ… è¾“å…¥éªŒè¯"):
        if fraction_type in ["ä½“ç§¯åˆ†æ•°", "è´¨é‡åˆ†æ•°"]:
            if abs(total - 100.0) > 1e-6:
                st.error(f"â— {fraction_type}çš„æ€»å’Œå¿…é¡»ä¸º100%ï¼ˆå½“å‰ï¼š{total:.2f}%ï¼‰")
            else:
                st.success(f"{fraction_type}æ€»å’ŒéªŒè¯é€šè¿‡")
        else:
            st.success("æˆåˆ†æ€»å’ŒéªŒè¯é€šè¿‡")
        if is_only_pp:
            st.info("æ£€æµ‹åˆ°çº¯PPé…æ–¹")

    with st.expander("ğŸ” æ¨¡å‹éªŒè¯ï¼ˆè´¨é‡åˆ†æ•°å‚è€ƒæ ·æœ¬ï¼‰", expanded=True):
        st.markdown("### æ ‡å‡†å‚è€ƒæ ·æœ¬éªŒè¯ï¼ˆè´¨é‡åˆ†æ•°åŸºå‡†ï¼‰")

        reference_samples = {
            "é˜»ç‡ƒPP-1": {
                "composition": {
                    "PP": 61.7, "PAPP": 23.0, "MPP": 9.0, "wollastonite": 5.0, "ZS": 1.0, "Anti-drip-agent": 0.3,
                },
                "actual": {"LOI": 43, "TS": 15.832}
            },
            "é˜»ç‡ƒPP-2": {
                "composition": {
                    "PP": 65.2, "PAPP": 23.0, "MPP": 7.0, "wollastonite": 3.0, "ZS": 1.5, "Anti-drip-agent": 0.3,
                },
                "actual": {"LOI": 43, "TS": 16.94}
            },
            "é˜»ç‡ƒPP-3": {
                "composition": {
                    "PP": 59.7, "PAPP": 23.0, "MPP": 13.0, "wollastonite": 3.0, "ZS": 1.0, "Anti-drip-agent": 0.3,
                },
                "actual": {"LOI": 43, "TS": 15.289}
            }
        }

        cols = st.columns(3)
        for idx, (sample_name, sample_data) in enumerate(reference_samples.items()):
            with cols[idx]:
                st.markdown(f"##### {sample_name}")
                comp_df = pd.DataFrame(
                    [(k, f"{v}%") for k, v in sample_data["composition"].items()],
                    columns=["ææ–™", "è´¨é‡åˆ†æ•°"]
                )
                st.dataframe(comp_df, hide_index=True, use_container_width=True, height=200)

                if st.button(f"éªŒè¯ {sample_name}", key=f"verify_{sample_name}", help="ç‚¹å‡»è‡ªåŠ¨å¡«å……å¹¶éªŒè¯è¯¥æ ·æœ¬"):
                    input_values.clear()
                    for material, percent in sample_data["composition"].items():
                        input_values[material] = percent

                    actual_loi = sample_data["actual"]["LOI"]
                    actual_ts = sample_data["actual"]["TS"]

                    try:
                        loi_input = np.array([[input_values.get(f, 0.0) for f in models["loi_features"]]])
                        loi_scaled = models["loi_scaler"].transform(loi_input)
                        pred_loi = models["loi_model"].predict(loi_scaled)[0]

                        ts_input = np.array([[input_values.get(f, 0.0) for f in models["ts_features"]]])
                        ts_scaled = models["ts_scaler"].transform(ts_input)
                        pred_ts = models["ts_model"].predict(ts_scaled)[0]

                        col1, col2 = st.columns(2)
                        with col1:
                            delta_loi = abs(pred_loi - actual_loi)
                            st.metric("LOIé¢„æµ‹å€¼", f"{pred_loi:.1f}%", delta=f"Î”{delta_loi:.1f}%", help=f"å®é™…å€¼: {actual_loi}%")
                        with col2:
                            delta_ts = abs(pred_ts - actual_ts)
                            st.metric("TSé¢„æµ‹å€¼", f"{pred_ts:.1f}MPa", delta=f"Î”{delta_ts:.1f}MPa", help=f"å®é™…å€¼: {actual_ts}MPa")

                        st.markdown(f"""
                            ###### è¯¯å·®åˆ†æ
                            - LOIç»å¯¹è¯¯å·®: `{delta_loi:.2f}%`  
                            - TSç»å¯¹è¯¯å·®: `{delta_ts:.2f}MPa`  
                            - LOIç›¸å¯¹è¯¯å·®: `{(delta_loi/actual_loi)*100:.1f}%`  
                            - TSç›¸å¯¹è¯¯å·®: `{(delta_ts/actual_ts)*100:.1f}%`
                        """)
                        loi_accuracy = 100 - (delta_loi/actual_loi)*100
                        ts_accuracy = 100 - (delta_ts/actual_ts)*100
                        
                        if loi_accuracy >= 85 and ts_accuracy >= 85:
                            st.success(f"âœ… æ¨¡å‹ç²¾åº¦è¶…è¿‡85%ï¼ˆLOIï¼š{loi_accuracy:.1f}%ï¼ŒTSï¼š{ts_accuracy:.1f}%ï¼‰")
                        else:
                            st.error(f"âš ï¸ æ¨¡å‹ç²¾åº¦æœªè¾¾æ ‡ï¼ˆLOIï¼š{loi_accuracy:.1f}%ï¼ŒTSï¼š{ts_accuracy:.1f}%ï¼‰")
                    except Exception as e:
                        st.error(f"éªŒè¯å¤±è´¥: {str(e)}")
                        st.stop()


    if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
        if fraction_type in ["ä½“ç§¯åˆ†æ•°", "è´¨é‡åˆ†æ•°"] and abs(total - 100.0) > 1e-6:
            st.error(f"é¢„æµ‹ä¸­æ­¢ï¼š{fraction_type}çš„æ€»å’Œå¿…é¡»ä¸º100%")
            st.stop()

        if is_only_pp:
            loi_pred = 17.5
            ts_pred = 35.0
        else:
            if fraction_type == "ä½“ç§¯åˆ†æ•°":
                vol_values = np.array(list(input_values.values()))
                mass_values = vol_values  # è‹¥æœ‰å¯†åº¦æ•°æ®å¯æ›¿æ¢æ­¤è¡Œ
                total_mass = mass_values.sum()
                input_values = {k: (v / total_mass * 100) for k, v in zip(input_values.keys(), mass_values)}

            for feature in models["loi_features"]:
                if feature not in input_values:
                    input_values[feature] = 0.0
            loi_input = np.array([[input_values[f] for f in models["loi_features"]]])
            loi_scaled = models["loi_scaler"].transform(loi_input)
            loi_pred = models["loi_model"].predict(loi_scaled)[0]

            for feature in models["ts_features"]:
                if feature not in input_values:
                    input_values[feature] = 0.0
            ts_input = np.array([[input_values[f] for f in models["ts_features"]]])
            ts_scaled = models["ts_scaler"].transform(ts_input)
            ts_pred = models["ts_model"].predict(ts_scaled)[0]

        col1, col2 = st.columns(2)
        with col1:
            st.metric(label="LOIé¢„æµ‹å€¼", value=f"{loi_pred:.2f}%")
        with col2:
            st.metric(label="TSé¢„æµ‹å€¼", value=f"{ts_pred:.2f} MPa")



# é…æ–¹å»ºè®®é¡µé¢
elif page == "é…æ–¹å»ºè®®":
    if sub_page == "é…æ–¹ä¼˜åŒ–":
        fraction_type = st.sidebar.radio(
            "ğŸ“ å•ä½ç±»å‹",
            ["è´¨é‡", "è´¨é‡åˆ†æ•°", "ä½“ç§¯åˆ†æ•°"],
            key="unit_type"
        )
        st.subheader("ğŸ§ª é…æ–¹å»ºè®®ï¼šæ ¹æ®æ€§èƒ½åæ¨é…æ–¹")
    
        col1, col2 = st.columns(2)
        with col1:
            target_loi = st.number_input("ç›®æ ‡LOIå€¼ï¼ˆ%ï¼‰", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
        with col2:
            target_ts = st.number_input("ç›®æ ‡TSå€¼ï¼ˆMPaï¼‰", min_value=10.0, max_value=100.0, value=50.0, step=0.1)
        
        with st.expander("âš™ï¸ ç®—æ³•å‚æ•°è®¾ç½®"):
            pop_size = st.number_input("ç§ç¾¤æ•°é‡", 50, 500, 200)
            n_gen = st.number_input("è¿­ä»£ä»£æ•°", 10, 100, 50)
            cx_prob = st.slider("äº¤å‰æ¦‚ç‡", 0.1, 1.0, 0.7)
            mut_prob = st.slider("å˜å¼‚æ¦‚ç‡", 0.1, 1.0, 0.2)
    
        if st.button("ğŸ” å¼€å§‹ä¼˜åŒ–", type="primary"):
            creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
            creator.create("Individual", list, fitness=creator.FitnessMin)
            
            toolbox = base.Toolbox()
            all_features = ensure_pp_first(list(set(models["loi_features"] + models["ts_features"])))
            n_features = len(all_features)
            
            def generate_individual():
                individual = [random.uniform(0, 100) for _ in range(n_features)]
                total = sum(individual)
                return [max(0, x / total * 100) for x in individual]
            
            toolbox.register("individual", tools.initIterate, creator.Individual, generate_individual)
            toolbox.register("population", tools.initRepeat, list, toolbox.individual)
            
            def evaluate(individual):
                if fraction_type == "ä½“ç§¯åˆ†æ•°":
                    vol_values = np.array(individual)
                    mass_values = vol_values
                    total_mass = mass_values.sum()
                    if total_mass == 0:
                        return (1e6,)
                    mass_percent = (mass_values / total_mass) * 100
                else:
                    total = sum(individual)
                    if total == 0:
                        return (1e6,)
                    mass_percent = np.array(individual) / total * 100
                
                pp_index = all_features.index("PP")
                pp_content = mass_percent[pp_index]
                if pp_content < 50:
                    return (1e6,)
                
                loi_input = mass_percent[:len(models["loi_features"])]
                loi_scaled = models["loi_scaler"].transform([loi_input])
                loi_pred = models["loi_model"].predict(loi_scaled)[0]
                loi_error = abs(target_loi - loi_pred)
                
                ts_input = mass_percent[:len(models["ts_features"])]
                ts_scaled = models["ts_scaler"].transform([ts_input])
                ts_pred = models["ts_model"].predict(ts_scaled)[0]
                ts_error = abs(target_ts - ts_pred)
                total = sum(mass_percent)
                if abs(total - 100) > 1e-6:
                    return (1e6,)
                return (loi_error + ts_error,)
            
            toolbox.register("mate", tools.cxBlend, alpha=0.5)
            toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)
            toolbox.register("select", tools.selTournament, tournsize=3)
            toolbox.register("evaluate", evaluate)
            
            population = toolbox.population(n=pop_size)
            algorithms.eaSimple(population, toolbox, cxpb=cx_prob, mutpb=mut_prob, ngen=n_gen, verbose=False)
            
            best_individuals = tools.selBest(population, 10)
            best_values = []
            for individual in best_individuals:
                total = sum(individual)
                best_values.append([round(max(0, i / total * 100), 2) for i in individual])  # ä¿®æ­£æ‹¬å·é—­åˆ
            
            result_df = pd.DataFrame(best_values, columns=all_features)
            units = [get_unit(fraction_type) for _ in all_features]
            result_df.columns = [f"{col} ({unit})" for col, unit in zip(result_df.columns, units)]
            st.write(result_df)
    
    elif sub_page == "æ·»åŠ å‰‚æ¨è":
        st.subheader("ğŸ§ª PVCæ·»åŠ å‰‚æ™ºèƒ½æ¨è")
        try:
            predictor = Predictor("scaler_fold_1.pkl", "svc_fold_1.pkl")
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.stop()
        with st.expander("ğŸ“š å‚è€ƒæ ·æœ¬æ•°æ®ï¼ˆç‚¹å‡»å±•å¼€ï¼‰"):
            st.markdown("""
            ### å…¸å‹æ ·æœ¬æ•°æ®å‚è€ƒ
            ä»¥ä¸‹ä¸ºéªŒè¯æ¨¡å‹æ•ˆæœçš„æ ‡å‡†æ ·æœ¬æ•°æ®ï¼š
            """)
            
            # æ ·æœ¬æ•°æ®å®šä¹‰
            sample_data = {
                "æ ·æœ¬åç§°": ["æ— æ·»åŠ å‰‚æ ·æœ¬", "æ°¯åŒ–çŸ³èœ¡æ ·æœ¬", "EA15æ ·æœ¬"],
                "æ ·æœ¬è¯´æ˜": [
                    "é¢„æœŸç»“æœï¼šæ— æ¨èæ·»åŠ å‰‚",
                    "é¢„æœŸç»“æœï¼šæ°¯åŒ–çŸ³èœ¡",
                    "é¢„æœŸç»“æœï¼šEA15ï¼ˆå¸‚å”®æ¶²ä½“é’™é”Œç¨³å®šå‰‚ï¼‰"
                ],
                "æ•°æ®æ˜ç»†": [
                    [19.2, 0, 32, 5.36, 6.29, 7.57, 8.57, 10.26, 13.21, 16.54, 27.47],
                    [18.5, 3.64, 31.05, 5.29, 6.83, 8.00, 9.32, 11.40, 14.12, 18.37, 30.29],
                    [19, 1.04, 31.88, 5.24, 6.17, 7.11, 8.95, 10.33, 13.21, 17.48, 28.08]
                ]
            }
            
        # åˆ›å»ºå±•ç¤ºè¡¨æ ¼
        for i in range(3):
            cols = st.columns([0.2, 1, 3])
            with cols[0]:
                st.metric(label="æ ·æœ¬ç¼–å·", value=f"#{i+1}")
            with cols[1]:
                st.markdown(f"""
                **{sample_data['æ ·æœ¬åç§°'][i]}**  
                {sample_data['æ ·æœ¬è¯´æ˜'][i]}
                """)
            with cols[2]:
                df = pd.DataFrame(
                    [sample_data['æ•°æ®æ˜ç»†'][i]],
                    columns=["Sn%", "æ·»åŠ æ¯”ä¾‹", "ä¸€ç”²%", 
                            "3min", "6min", "9min", "12min",
                            "15min", "18min", "21min", "24min"]
                ).T.reset_index()
                df.columns = ["å‚æ•°", "æ•°å€¼"]
                st.dataframe(df.style.format({"æ•°å€¼": "{:.2f}"}), 
                           height=300,
                           use_container_width=True)
            st.markdown("---")
        with st.form("additive_form"):
            example_options = {
            "æ— æ·»åŠ å‰‚æ ·æœ¬": [19.2, 0, 32, 5.36, 6.29, 7.57, 8.57, 10.26, 13.21, 16.54, 27.47],
            "æ°¯åŒ–çŸ³èœ¡æ ·æœ¬": [18.5, 3.64, 31.05, 5.29, 6.83, 8.00, 9.32, 11.40, 14.12, 18.37, 30.29],
            "EA15æ ·æœ¬": [19, 1.041666667, 31.88, 5.24, 6.17, 7.11, 8.95, 10.33, 13.21, 17.48, 28.08]
        }
            
            # åŸºç¡€å‚æ•°
            col1, col2, col3 = st.columns(3)
            with col1: sn = st.number_input("Sn%", 0.0, 100.0, 5.0)
            with col2: ratio = st.number_input("æ·»åŠ æ¯”ä¾‹", 0.0, 100.0, 14.0)
            with col3: yijia = st.number_input("ä¸€ç”²%", 0.0, 100.0, 23.55)
            
            # æ—¶åºå‚æ•°ï¼ˆä¿®æ”¹éƒ¨åˆ†ï¼‰
            st.markdown("### é»„åº¦å€¼æ—¶åºå‚æ•°ï¼ˆ0-50ï¼‰")
            time_points = ["3min", "6min", "9min", "12min", "15min", "18min", "21min", "24min"]
            yellow = {}
            cols = st.columns(4)
            
            for idx, t in enumerate(time_points):
                with cols[idx%4]:
                    yellow[t] = st.number_input(
                        f"{t} é»„åº¦å€¼",
                        min_value=0.0,    # ä¿®æ”¹æœ€å°å€¼å›ºå®šä¸º0
                        max_value=50.0,   # ä¿®æ”¹æœ€å¤§å€¼è°ƒæ•´ä¸º50
                        value=15.0+idx,   # é»˜è®¤å€¼ä¿æŒä¸å˜
                        key=f"yellow_{t}"
                    )
            
            # æäº¤æŒ‰é’®
            if st.form_submit_button("ç”Ÿæˆæ¨è"):
                try:
                    # æ„å»ºè¾“å…¥æ ·æœ¬ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    sample = [sn, ratio, yijia] + [yellow[t] for t in time_points]
                    
                    # æ‰§è¡Œé¢„æµ‹ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    pred = predictor.predict_one(sample)
                    
                    # æ˜¾ç¤ºç»“æœï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    result_map = {
                        1: "æ— æ¨èæ·»åŠ å‰‚", 2: "æ°¯åŒ–çŸ³èœ¡", 3: "EA12", 
                        4: "EA15", 5: "EA16", 6: "G70L", 7: "EA6"
                    }
                    additive = result_map.get(pred, "æœªçŸ¥")
                    
                    # æ„å»ºå±•ç¤ºæ•°æ®ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    formula = [
                        ["PVCä»½æ•°", 100.0], ["ACRä»½æ•°", 1.0], ["70Sä»½æ•°", 0.35],
                        ["MBSä»½æ•°", 5.0], ["316Aä»½æ•°", 0.2], ["ç¨³å®šå‰‚ä»½æ•°", 1.0],
                        ["ä¸€ç”²%", yijia], ["Sn%", sn]
                    ]
                    if pred != 1:
                        formula.extend([[f"{additive}å«é‡", f"{ratio if pred!=1 else 0}%"]])
    
                    # æ˜¾ç¤ºç»“æœï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("æ¨èç»“æœ", additive)
                    with col2:
                        st.dataframe(pd.DataFrame(formula, columns=["ææ–™", "å«é‡"]), 
                                   hide_index=True)
                            
                except Exception as e:
                    st.error(f"é¢„æµ‹é”™è¯¯: {str(e)}")
# æ·»åŠ é¡µè„š
def add_footer():
    st.markdown("""
    <hr>
    <footer style="text-align: center;">
        <p>Â© 2025 é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°</p>
        <p>å¼€å‘è€…: é©¬ç»´å®¾</p>
        <p>å¹³å°æ€§è´¨å£°æ˜ï¼šæœ¬å¹³å°ä¸ºç§‘ç ”åä½œç½‘ç»œæœåŠ¡å¹³å°ï¼Œæ‰€æœ‰å†…å®¹ä»…ä¾›å­¦æœ¯ç ”ç©¶ã€æŠ€æœ¯éªŒè¯ç­‰éè¥åˆ©æ€§ç§‘ç ”æ´»åŠ¨ä½¿ç”¨ï¼Œä¸¥ç¦ç”¨äºä»»ä½•å•†ä¸šç”¨é€”ã€‚</p>
    </footer>
    """, unsafe_allow_html=True)

add_footer() 
