import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
from deap import base, creator, tools, algorithms
import base64

# Function to convert image to base64
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# è®¾ç½®é¡µé¢é…ç½®ï¼ˆä¿æŒåŸæ ·ï¼Œå›¾æ ‡ä¾ç„¶æ˜¯æ˜¾ç¤ºåœ¨æµè§ˆå™¨æ ‡ç­¾é¡µä¸­ï¼‰
image_path = "å›¾ç‰‡1.png"  # ä½¿ç”¨ä¸Šä¼ çš„å›¾ç‰‡è·¯å¾„
icon_base64 = image_to_base64(image_path)  # è½¬æ¢ä¸º base64

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(page_title="èšä¸™çƒ¯LOIæ¨¡å‹", layout="wide", page_icon=f"data:image/png;base64,{icon_base64}")

# å›¾æ ‡åŸå§‹å°ºå¯¸ï¼š507x158ï¼Œè®¡ç®—å‡ºæ¯”ä¾‹
width = 200  # è®¾ç½®å›¾æ ‡çš„å®½åº¦ä¸º100px
height = int(158 * (width / 507))  # è®¡ç®—ä¿æŒæ¯”ä¾‹åçš„é«˜åº¦

# åœ¨é¡µé¢ä¸Šæ’å…¥å›¾æ ‡ä¸æ ‡é¢˜
st.markdown(
    f"""
    <h1 style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{icon_base64}" style="width: {width}px; height: {height}px; margin-right: 15px;" />
        é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°
    </h1>
    """, 
    unsafe_allow_html=True
)

page = st.sidebar.selectbox("ğŸ”§ é€‰æ‹©åŠŸèƒ½", ["æ€§èƒ½é¢„æµ‹", "é…æ–¹å»ºè®®"])

# åŠ è½½æ¨¡å‹ä¸ç¼©æ”¾å™¨
data = joblib.load("model_and_scaler_loi.pkl")
model = data["model"]
scaler = data["scaler"]

df = pd.read_excel("trainrg3.xlsx")
feature_names = df.columns.tolist()
if "LOI" in feature_names:
    feature_names.remove("LOI")

unit_type = st.radio("ğŸ“ è¯·é€‰æ‹©é…æ–¹è¾“å…¥å•ä½", ["è´¨é‡ (g)", "è´¨é‡åˆ†æ•° (wt%)", "ä½“ç§¯åˆ†æ•° (vol%)"], horizontal=True)

if page == "æ€§èƒ½é¢„æµ‹":
    st.subheader("ğŸ”¬ æ­£å‘é¢„æµ‹ï¼šé…æ–¹ â†’ LOI")

    with st.form("input_form"):
        user_input = {}
        total = 0
        cols = st.columns(3)
        for i, name in enumerate(feature_names):
            unit_label = {
                "è´¨é‡ (g)": "g",
                "è´¨é‡åˆ†æ•° (wt%)": "wt%",
                "ä½“ç§¯åˆ†æ•° (vol%)": "vol%"
            }[unit_type]
            val = cols[i % 3].number_input(f"{name} ({unit_label})", value=0.0, step=0.1 if "è´¨é‡" in unit_type else 0.01)
            user_input[name] = val
            total += val

        submitted = st.form_submit_button("ğŸ“Š å¼€å§‹é¢„æµ‹")

    if submitted:
        # åˆ¤æ–­æ€»å’Œæ˜¯å¦æ»¡è¶³ä¸º100
        if unit_type != "è´¨é‡ (g)" and abs(total - 100) > 1e-3:
            st.warning("âš ï¸ é…æ–¹åŠ å’Œä¸ä¸º100ï¼Œæ— æ³•é¢„æµ‹ã€‚è¯·ç¡®ä¿æ€»å’Œä¸º100åå†è¿›è¡Œé¢„æµ‹ã€‚")
        else:
            # è‹¥æ˜¯åˆ†æ•°å•ä½ï¼Œåˆ™å†å½’ä¸€åŒ–ä¸€é
            if unit_type == "è´¨é‡ (g)" and total > 0:  # åˆ¤æ–­æ˜¯å¦ä¸ºè´¨é‡å•ä½
                # å°†æ¯ä¸ªæˆåˆ†çš„è´¨é‡è½¬æ¢ä¸ºè´¨é‡åˆ†æ•°
                user_input = {k: (v / total) * 100 for k, v in user_input.items()}  # å½’ä¸€åŒ–ä¸ºè´¨é‡åˆ†æ•°

            elif unit_type != "è´¨é‡ (g)" and total > 0:
                user_input = {k: v / total * 100 for k, v in user_input.items()}  # ç¡®ä¿æ€»å’Œä¸º100

            # æ£€æŸ¥æ˜¯å¦ä»…è¾“å…¥äº†PPï¼Œå¹¶ä¸”PPä¸º100
            if np.all([user_input.get(name, 0) == 0 for name in feature_names if name != "PP"]) and user_input.get("PP", 0) == 100:
                # å¦‚æœåªè¾“å…¥äº†PPä¸”PPä¸º100ï¼Œå¼ºåˆ¶è¿”å›LOI=17.5
                st.markdown("### ğŸ¯ é¢„æµ‹ç»“æœ")
                st.metric(label="æé™æ°§æŒ‡æ•° (LOI)", value="17.5 %")
            else:
                input_array = np.array([list(user_input.values())])
                input_scaled = scaler.transform(input_array)
                prediction = model.predict(input_scaled)[0]

                st.markdown("### ğŸ¯ é¢„æµ‹ç»“æœ")
                st.metric(label="æé™æ°§æŒ‡æ•° (LOI)", value=f"{prediction:.2f} %")

elif page == "é…æ–¹å»ºè®®":
    target_loi = st.number_input("ğŸ¯ è¯·è¾“å…¥ç›®æ ‡ LOI å€¼ (%)", value=20.0, step=0.1, min_value=10.0, max_value=40.0)
    output_mode = st.selectbox("ğŸ“¦ è¯·é€‰æ‹©è¾“å‡ºå½¢å¼", ["è´¨é‡åˆ†æ•°ï¼ˆwt%ï¼‰", "è´¨é‡ï¼ˆgï¼‰", "ä½“ç§¯åˆ†æ•°ï¼ˆvol%ï¼‰"])

    if target_loi < 10 or target_loi > 40:
        st.warning("âš ï¸ ç›®æ ‡ LOI å€¼å¿…é¡»åœ¨ 10 åˆ° 40 ä¹‹é—´ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
    else:
        st.write("ğŸ”„ æ­£åœ¨è¿›è¡Œé€†å‘è®¾è®¡ï¼Œè¯·ç¨ç­‰...")

        pp_index = feature_names.index("PP")
        num_features = len(feature_names)

        creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
        creator.create("Individual", list, fitness=creator.FitnessMin)

        def make_valid_individual():
            ind = np.random.uniform(0.1, 1, num_features)
            ind[pp_index] = max(ind) + 0.1
            ind = np.clip(ind, 0, None)
            return creator.Individual(ind)

        def evaluate(ind):
            ind = np.clip(ind, 0, None)
            if ind[pp_index] <= max([x for i, x in enumerate(ind) if i != pp_index]):
                return 1e6,
            norm = ind / np.sum(ind) * 100  # ç¡®ä¿åŠ å’Œä¸º100
            X_scaled = scaler.transform([norm])
            y_pred = model.predict(X_scaled)[0]
            return abs(y_pred - target_loi),

        toolbox = base.Toolbox()
        toolbox.register("individual", make_valid_individual)
        toolbox.register("population", tools.initRepeat, list, toolbox.individual)
        toolbox.register("evaluate", evaluate)
        toolbox.register("mate", tools.cxBlend, alpha=0.5)
        toolbox.register("mutate", tools.mutGaussian, mu=0.0, sigma=0.1, indpb=0.3)
        toolbox.register("select", tools.selTournament, tournsize=3)

        pop = toolbox.population(n=100)
        hof = tools.HallOfFame(20)

        algorithms.eaSimple(pop, toolbox, cxpb=0.7, mutpb=0.3, ngen=60, halloffame=hof, verbose=False)

        results = []
        for ind in hof:
            ind = np.clip(ind, 0, None)
            norm = ind / np.sum(ind) * 100
            if norm[pp_index] <= max([x for i, x in enumerate(norm) if i != pp_index]):
                continue
            pred_loi = model.predict(scaler.transform([norm]))[0]
            results.append(list(norm) + [pred_loi])

        if len(results) == 0:
            st.error("âŒ æœªèƒ½ç”Ÿæˆç¬¦åˆæ¡ä»¶çš„é…æ–¹ï¼Œè¯·å°è¯•è°ƒæ•´ç›®æ ‡å€¼æˆ–æ”¾å®½æ¡ä»¶ã€‚")
        else:
            df_result = pd.DataFrame(results[:10], columns=feature_names + ["é¢„æµ‹ LOI"])

            if output_mode == "è´¨é‡ï¼ˆgï¼‰":
                df_result.iloc[:, :-1] = df_result.iloc[:, :-1] * 1.0  # æ€»è´¨é‡100g
                df_result.columns = [f"{col} (g)" if col != "é¢„æµ‹ LOI" else col for col in df_result.columns]
            elif output_mode == "è´¨é‡åˆ†æ•°ï¼ˆwt%ï¼‰":
                df_result.columns = [f"{col} (wt%)" if col != "é¢„æµ‹ LOI" else col for col in df_result.columns]
            elif output_mode == "ä½“ç§¯åˆ†æ•°ï¼ˆvol%ï¼‰":
                volume_fractions = df_result.iloc[:, :-1].div(df_result.iloc[:, :-1].sum(axis=1), axis=0) * 100
                df_result.iloc[:, :-1] = volume_fractions
                df_result.columns = [f"{col} (vol%)" if col != "é¢„æµ‹ LOI" else col for col in df_result.columns]

            st.markdown("### ğŸ“‹ æ¨èé…æ–¹")
            st.dataframe(df_result.round(2))
