import pandas as pd
import numpy as np
import warnings
from scipy import stats
from scipy.stats import kurtosis, skew
from sklearn.impute import SimpleImputer
import joblib

class Predictor:
    def __init__(self, scaler_path, svc_path):
        self.scaler = joblib.load(scaler_path)
        self.model = joblib.load(svc_path)
        
        # ç‰¹å¾åˆ—é…ç½®
        self.static_cols = ["äº§å“è´¨é‡æŒ‡æ ‡_Sn%", "æ·»åŠ æ¯”ä¾‹", "ä¸€ç”²%"]
        self.time_series_cols = [
            "é»„åº¦å€¼_3min", "6min", "9min", "12min",
            "15min", "18min", "21min", "24min"
        ]
        self.eng_features = [
            'seq_length', 'max_value', 'mean_value', 'min_value',
            'std_value', 'trend', 'range_value', 'autocorr'
        ]
        self.imputer = SimpleImputer(strategy="mean")

    def _truncate(self, df):
        time_cols = [col for col in df.columns if "min" in col.lower()]
        time_cols_ordered = [col for col in df.columns if col in time_cols]
        if time_cols_ordered:
            row = df.iloc[0][time_cols_ordered]
            if row.notna().any():
                max_idx = row.idxmax()
                max_pos = time_cols_ordered.index(max_idx)
                for col in time_cols_ordered[max_pos + 1:]:
                    df.at[df.index[0], col] = np.nan
        return df
    
    def _get_slope(self, row, col=None):
        # col æ˜¯å¯é€‰çš„ï¼Œå°†è¢«å¿½ç•¥
        x = np.arange(len(row))
        y = row.values
        mask = ~np.isnan(y)
        if sum(mask) >= 2:
            return stats.linregress(x[mask], y[mask])[0]
        return np.nan
    def _calc_autocorr(self, row):
        """è®¡ç®—ä¸€é˜¶è‡ªç›¸å…³ç³»æ•°"""
        # å»é™¤NaNå€¼
        values = row.dropna().values
        if len(values) > 1:
            # è®¡ç®—ä¸€é˜¶è‡ªç›¸å…³ç³»æ•°
            n = len(values)
            mean = np.mean(values)
            # è®¡ç®—åæ–¹å·®å’Œæ–¹å·®
            numerator = sum((values[:-1] - mean) * (values[1:] - mean))
            denominator = sum((values - mean) ** 2)
            if denominator != 0:
                return numerator / denominator
        return np.nan

    def _extract_time_series_features(self, df):
        """ä¿®å¤åçš„æ—¶åºç‰¹å¾æå–"""
        time_data = df[self.time_series_cols]
        time_data_filled = time_data.ffill(axis=1)  # âœ… æ²¿æ—¶é—´è½´å¡«å……
        
        features = pd.DataFrame()
        features['seq_length'] = time_data_filled.notna().sum(axis=1)
        features['max_value'] = time_data_filled.max(axis=1)
        features['mean_value'] = time_data_filled.mean(axis=1)
        features['min_value'] = time_data_filled.min(axis=1)
        features['std_value'] = time_data_filled.std(axis=1)
        features['range_value'] = features['max_value'] - features['min_value']
        features['trend'] = time_data_filled.apply(self._get_slope, axis=1)
        features['autocorr'] = time_data_filled.apply(self._calc_autocorr, axis=1)
        return features

    def predict_one(self, sample):
        full_cols = self.static_cols + self.time_series_cols
        df = pd.DataFrame([sample], columns=full_cols)
        df = self._truncate(df)  # âœ… è°ƒç”¨å·²å®šä¹‰çš„æ–¹æ³•
        
        # ç‰¹å¾åˆå¹¶
        static_features = df[self.static_cols]
        time_features = self._extract_time_series_features(df)
        feature_df = pd.concat([static_features, time_features], axis=1)
        feature_df = feature_df[self.static_cols + self.eng_features]  # âœ… ç¡®ä¿åˆ—é¡ºåº
        
        # éªŒè¯ç»´åº¦
        if feature_df.shape[1] != self.scaler.n_features_in_:
            raise ValueError(f"ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼å½“å‰ï¼š{feature_df.shape[1]}ï¼Œéœ€è¦ï¼š{self.scaler.n_features_in_}")
        
        X_scaled = self.scaler.transform(feature_df)
        return self.model.predict(X_scaled)[0]

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import base64
import random
from deap import base, creator, tools, algorithms

# è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬base64
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# é¡µé¢é…ç½®
image_path = "å›¾ç‰‡1.png"
icon_base64 = image_to_base64(image_path)
st.set_page_config(
    page_title="èšä¸™çƒ¯LOIå’ŒTSæ¨¡å‹",
    layout="wide",
    page_icon=f"data:image/png;base64,{icon_base64}"
)

# é¡µé¢æ ‡é¢˜æ ·å¼
width = 200
height = int(158 * (width / 507))
st.markdown(
    f"""
    <h1 style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{icon_base64}" style="width: {width}px; height: {height}px; margin-right: 15px;" />
        é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°
    </h1>
    """, 
    unsafe_allow_html=True
)


# ä¾§è¾¹æ ä¸»å¯¼èˆª
page = st.sidebar.selectbox(
    "ğŸ”§ ä¸»åŠŸèƒ½é€‰æ‹©",
    ["æ€§èƒ½é¢„æµ‹", "é…æ–¹å»ºè®®"],
    key="main_nav"
)

# å­åŠŸèƒ½é€‰æ‹©ï¼ˆä»…åœ¨é…æ–¹å»ºè®®æ—¶æ˜¾ç¤ºï¼‰
sub_page = None
if page == "é…æ–¹å»ºè®®":
    sub_page = st.sidebar.selectbox(
        "ğŸ”§ å­åŠŸèƒ½é€‰æ‹©",
        ["é…æ–¹ä¼˜åŒ–", "æ·»åŠ å‰‚æ¨è"],
        key="sub_nav"
    )

# å•ä½ç±»å‹é€‰æ‹©ï¼ˆåŠ¨æ€æ˜¾ç¤ºï¼‰
if page == "æ€§èƒ½é¢„æµ‹" or (page == "é…æ–¹å»ºè®®" and sub_page == "é…æ–¹ä¼˜åŒ–"):
    fraction_type = st.sidebar.radio(
        "ğŸ“ å•ä½ç±»å‹",
        ["è´¨é‡", "è´¨é‡åˆ†æ•°", "ä½“ç§¯åˆ†æ•°"],
        key="unit_type"
    )
else:
    fraction_type = None

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_models():
    loi_data = joblib.load("model_and_scaler_loi.pkl")
    ts_data = joblib.load("model_and_scaler_ts1.pkl")
    return {
        "loi_model": loi_data["model"],
        "loi_scaler": loi_data["scaler"],
        "ts_model": ts_data["model"],
        "ts_scaler": ts_data["scaler"],
        "loi_features": pd.read_excel("trainrg3.xlsx").drop(columns="LOI", errors='ignore').columns.tolist(),
        "ts_features": pd.read_excel("trainrg3TS.xlsx").drop(columns="TS", errors='ignore').columns.tolist(),
    }
models = load_models()

# è·å–å•ä½
def get_unit(fraction_type):
    if fraction_type == "è´¨é‡":
        return "g"
    elif fraction_type == "è´¨é‡åˆ†æ•°":
        return "wt%"
    elif fraction_type == "ä½“ç§¯åˆ†æ•°":
        return "vol%"

# ä¿è¯PPåœ¨é¦–åˆ—
def ensure_pp_first(features):
    if "PP" in features:
        features.remove("PP")
    return ["PP"] + sorted(features)

# æ€§èƒ½é¢„æµ‹é¡µé¢
if page == "æ€§èƒ½é¢„æµ‹":
    st.subheader("ğŸ”® æ€§èƒ½é¢„æµ‹ï¼šåŸºäºé…æ–¹é¢„æµ‹LOIå’ŒTS")
    
    # å®šä¹‰åˆ†ç±»çš„ææ–™
    matrix_materials = [
        "PP",  "PA","PC/ABS","POM","PBT","PVC","å…¶ä»–"
    ]
    flame_retardants = [
       "AHP"ï¼Œ"ammonium octamolybdate", "Al(OH)3", "CFA", "APP", "Pentaerythritol","DOPO", "EPFR-1100NT", "XS-FR-8310", "ZS", "XiuCheng", "ZHS", "ZnB", "antimony oxides"ï¼Œ"Mg(OH)2", "TCA", "MPP", "PAPP",
    ,"å…¶ä»–"]
    additives = [
        "wollastonite", "M-2200B", "ZBS-PV-OA", "FP-250S",  "silane coupling agent",  "antioxidant"ï¼Œ "SiO2","å…¶ä»–"
    ]
    
    # ç”¨æˆ·é€‰æ‹©çš„å•ä½ç±»å‹
    fraction_type = st.selectbox("é€‰æ‹©è¾“å…¥çš„å•ä½", ["è´¨é‡", "è´¨é‡åˆ†æ•°", "ä½“ç§¯åˆ†æ•°"])
    
    # æ˜¾ç¤ºåˆ†ç±»é€‰æ‹©ï¼šåŸºä½“ã€é˜»ç‡ƒå‰‚å’ŒåŠ©å‰‚çš„ä¸‹æ‹‰èœå•
    st.subheader("è¯·é€‰æ‹©é…æ–¹ä¸­çš„åŸºä½“ã€é˜»ç‡ƒå‰‚å’ŒåŠ©å‰‚")
    
    # åŸºä½“ã€é˜»ç‡ƒå‰‚å’ŒåŠ©å‰‚çš„ä¸‹æ‹‰èœå•
    selected_matrix = st.selectbox("é€‰æ‹©åŸºä½“", matrix_materials)
    selected_flame_retardant = st.selectbox("é€‰æ‹©é˜»ç‡ƒå‰‚", flame_retardants)
    selected_additive = st.selectbox("é€‰æ‹©åŠ©å‰‚", additives)
    
    # è¾“å…¥å…¶ä»–ææ–™çš„æ•°é‡ï¼ˆå‡è®¾æŒ‰è´¨é‡åˆ†æ•°ï¼‰
    input_values = {}
    input_values["matrix"] = st.number_input(f"é€‰æ‹© {selected_matrix} çš„è´¨é‡åˆ†æ•° (%)", min_value=0.0, max_value=100.0, value=50.0, step=0.1)
    input_values["flame_retardant"] = st.number_input(f"é€‰æ‹© {selected_flame_retardant} çš„è´¨é‡åˆ†æ•° (%)", min_value=0.0, max_value=100.0, value=20.0, step=0.1)
    input_values["additive"] = st.number_input(f"é€‰æ‹© {selected_additive} çš„è´¨é‡åˆ†æ•° (%)", min_value=0.0, max_value=100.0, value=30.0, step=0.1)
    
    # è¾“å…¥éªŒè¯
    total = sum(input_values.values())
    is_only_pp = all(v == 0 for k, v in input_values.items() if k != "PP")
    
    with st.expander("âœ… è¾“å…¥éªŒè¯"):
        if fraction_type == "ä½“ç§¯åˆ†æ•°":
            if abs(total - 100.0) > 1e-6:
                st.error(f"â— ä½“ç§¯åˆ†æ•°çš„æ€»å’Œå¿…é¡»ä¸º100%ï¼ˆå½“å‰ï¼š{total:.2f}%ï¼‰")
            else:
                st.success("ä½“ç§¯åˆ†æ•°æ€»å’ŒéªŒè¯é€šè¿‡")
        elif fraction_type == "è´¨é‡åˆ†æ•°":
            if abs(total - 100.0) > 1e-6:
                st.error(f"â— è´¨é‡åˆ†æ•°çš„æ€»å’Œå¿…é¡»ä¸º100%ï¼ˆå½“å‰ï¼š{total:.2f}%ï¼‰")
            else:
                st.success("è´¨é‡åˆ†æ•°æ€»å’ŒéªŒè¯é€šè¿‡")
        else:
            st.success("æˆåˆ†æ€»å’ŒéªŒè¯é€šè¿‡")
            if is_only_pp:
                st.info("æ£€æµ‹åˆ°çº¯PPé…æ–¹")

    if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
        if fraction_type == "ä½“ç§¯åˆ†æ•°" and abs(total - 100.0) > 1e-6:
            st.error("é¢„æµ‹ä¸­æ­¢ï¼šä½“ç§¯åˆ†æ•°çš„æ€»å’Œå¿…é¡»ä¸º100%")
            st.stop()
        elif fraction_type == "è´¨é‡åˆ†æ•°" and abs(total - 100.0) > 1e-6:
            st.error("é¢„æµ‹ä¸­æ­¢ï¼šè´¨é‡åˆ†æ•°çš„æ€»å’Œå¿…é¡»ä¸º100%")
            st.stop()

        # å¦‚æœæ˜¯çº¯PPé…æ–¹ï¼Œç›´æ¥è¿›è¡ŒLOIå’ŒTSé¢„æµ‹
        if is_only_pp:
            loi_pred = 17.5  # å‡è®¾PPé…æ–¹LOIä¸º17.5%
            ts_pred = 35.0  # å‡è®¾PPé…æ–¹TSä¸º35 MPa
        else:
            # å•ä½è½¬æ¢å¤„ç†
            if fraction_type == "ä½“ç§¯åˆ†æ•°":
                # ä½“ç§¯åˆ†æ•°è½¬åŒ–ä¸ºè´¨é‡åˆ†æ•°
                vol_values = np.array([input_values[f] for f in ["matrix", "flame_retardant", "additive"]])
                mass_values = vol_values  # å‡è®¾ä½“ç§¯åˆ†æ•°ä¸è´¨é‡åˆ†æ•°ç›´æ¥ç›¸ç­‰
                total_mass = mass_values.sum()
                input_values = {f: (mass_values[i]/total_mass)*100 for i, f in enumerate(["matrix", "flame_retardant", "additive"])}
            
            # LOIé¢„æµ‹
            loi_input = np.array([[input_values[f] for f in models["loi_features"]]])
            loi_scaled = models["loi_scaler"].transform(loi_input)
            loi_pred = models["loi_model"].predict(loi_scaled)[0]
        
            # TSé¢„æµ‹
            ts_input = np.array([[input_values[f] for f in models["ts_features"]]])
            ts_scaled = models["ts_scaler"].transform(ts_input)
            ts_pred = models["ts_model"].predict(ts_scaled)[0]
        
        # æ˜¾ç¤ºç»“æœ
        col1, col2 = st.columns(2)
        with col1:
            st.metric(label="LOIé¢„æµ‹å€¼", value=f"{loi_pred:.2f}%")
        with col2:
            st.metric(label="TSé¢„æµ‹å€¼", value=f"{ts_pred:.2f} MPa")


elif page == "é…æ–¹å»ºè®®":
    sub_page = st.sidebar.selectbox("ğŸ”§ é€‰æ‹©åŠŸèƒ½", ["","é…æ–¹ä¼˜åŒ–", "æ·»åŠ å‰‚æ¨è"])
    if sub_page == "é…æ–¹ä¼˜åŒ–":
        st.subheader("ğŸ§ª é…æ–¹å»ºè®®ï¼šæ ¹æ®æ€§èƒ½åæ¨é…æ–¹")
    
        # ç›®æ ‡è¾“å…¥
        col1, col2 = st.columns(2)
        with col1:
            target_loi = st.number_input("ç›®æ ‡LOIå€¼ï¼ˆ%ï¼‰", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
        with col2:
            target_ts = st.number_input("ç›®æ ‡TSå€¼ï¼ˆMPaï¼‰", min_value=0.0, max_value=100.0, value=50.0, step=0.1)
        
        # é—ä¼ ç®—æ³•å‚æ•°
        with st.expander("âš™ï¸ ç®—æ³•å‚æ•°è®¾ç½®"):
            pop_size = st.number_input("ç§ç¾¤æ•°é‡", 50, 500, 200)
            n_gen = st.number_input("è¿­ä»£ä»£æ•°", 10, 100, 50)
            cx_prob = st.slider("äº¤å‰æ¦‚ç‡", 0.1, 1.0, 0.7)
            mut_prob = st.slider("å˜å¼‚æ¦‚ç‡", 0.1, 1.0, 0.2)
    
        if st.button("ğŸ” å¼€å§‹ä¼˜åŒ–", type="primary"):
            # åˆå§‹åŒ–é—ä¼ ç®—æ³•
            creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
            creator.create("Individual", list, fitness=creator.FitnessMin)
            
            toolbox = base.Toolbox()
            all_features = ensure_pp_first(list(set(models["loi_features"] + models["ts_features"])))
            n_features = len(all_features)
            
            # ç”Ÿæˆæ»¡è¶³å’Œä¸º100çš„é…æ–¹
            def generate_individual():
                # éšæœºç”Ÿæˆä¸€ä¸ªå’Œä¸º100çš„é…æ–¹
                individual = [random.uniform(0, 100) for _ in range(n_features)]
                total = sum(individual)
                # ä¿è¯æ€»å’Œä¸º100ï¼Œä¸”ä¸å«è´Ÿå€¼
                return [max(0, x / total * 100) for x in individual]
            
            toolbox.register("individual", tools.initIterate, creator.Individual, generate_individual)
            toolbox.register("population", tools.initRepeat, list, toolbox.individual)
            
            def evaluate(individual):
                # å•ä½è½¬æ¢å¤„ç†
                if fraction_type == "ä½“ç§¯åˆ†æ•°":
                    # è½¬æ¢ä¸ºè´¨é‡åˆ†æ•°
                    vol_values = np.array(individual)
                    mass_values = vol_values  # ç›´æ¥ä½¿ç”¨ä½“ç§¯åˆ†æ•°æ¯”ä¾‹è¡¨ç¤ºè´¨é‡åˆ†æ•°
                    total_mass = mass_values.sum()
                    if total_mass == 0:
                        return (1e6,)
                    mass_percent = (mass_values / total_mass) * 100
                else:
                    total = sum(individual)
                    if total == 0:
                        return (1e6,)
                    mass_percent = np.array(individual) / total * 100
                
                # PPçº¦æŸ
                pp_index = all_features.index("PP")
                pp_content = mass_percent[pp_index]
                if pp_content < 50:  # PPå«é‡è¿‡ä½æƒ©ç½š
                    return (1e6,)
                
                # LOIè®¡ç®—
                loi_input = mass_percent[:len(models["loi_features"])]
                loi_scaled = models["loi_scaler"].transform([loi_input])
                loi_pred = models["loi_model"].predict(loi_scaled)[0]
                loi_error = abs(target_loi - loi_pred)
                
                # TSè®¡ç®—
                ts_input = mass_percent[:len(models["ts_features"])]
                ts_scaled = models["ts_scaler"].transform([ts_input])
                ts_pred = models["ts_model"].predict(ts_scaled)[0]
                ts_error = abs(target_ts - ts_pred)
                total = sum(mass_percent)
                if abs(total - 100) > 1e-6:
                    return (1e6,)
                return (loi_error + ts_error,)
            
            toolbox.register("mate", tools.cxBlend, alpha=0.5)
            toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)
            toolbox.register("select", tools.selTournament, tournsize=3)
            toolbox.register("evaluate", evaluate)
            
            population = toolbox.population(n=pop_size)
            algorithms.eaSimple(population, toolbox, cxpb=cx_prob, mutpb=mut_prob, ngen=n_gen, verbose=False)
            
            # é€‰æ‹©10ä¸ªé…æ–¹å¹¶ç¡®ä¿æ¯ä¸ªé…æ–¹çš„æ€»å’Œä¸º100
            best_individuals = tools.selBest(population, 10)
            best_values = []
            for individual in best_individuals:
                # ç¡®ä¿æ¯ä¸ªé…æ–¹çš„æ€»å’Œä¸º100ï¼Œå¹¶ä¿®æ­£è´Ÿå€¼
                total = sum(individual)
                best_values.append([round(max(0, i / total * 100), 2) for i in individual])
    
            # è¾“å‡ºä¼˜åŒ–ç»“æœ
            result_df = pd.DataFrame(best_values, columns=all_features)
            
            # æ·»åŠ å•ä½åˆ—
            units = [get_unit(fraction_type) for _ in all_features]
            result_df.columns = [f"{col} ({unit})" for col, unit in zip(result_df.columns, units)]
            
            st.write(result_df)
    elif sub_page == "æ·»åŠ å‰‚æ¨è":
        st.subheader("ğŸ§ª æ·»åŠ å‰‚æ™ºèƒ½æ¨è")

        @st.cache_resource
        def load_predictor():
            return Predictor(
                scaler_path="scaler_fold_1.pkl",
                svc_path="svc_fold_1.pkl"
            )

        predictor = load_predictor()

        with st.form("additive_form"):
            st.markdown("### åŸºç¡€å‚æ•°")
            col_static = st.columns(3)
            with col_static[0]:
                add_ratio = st.number_input("æ·»åŠ æ¯”ä¾‹ (%)", 0.0, 100.0, 5.0, step=0.1)
            with col_static[1]:
                sn_percent = st.number_input("Snå«é‡ (%)", 0.0, 100.0, 98.5, step=0.1)
            with col_static[2]:
                yijia_percent = st.number_input("ä¸€ç”²èƒºå«é‡ (%)", 0.0, 100.0, 0.5, step=0.1)

            st.markdown("### æ—¶åºå‚æ•°ï¼ˆé»„åº¦å€¼éšæ—¶é—´å˜åŒ–ï¼‰")

            time_points = [
                ("3min", 1.2), ("6min", 1.5), ("9min", 1.8),
                ("12min", 2.0), ("15min", 2.2), ("18min", 2.5),
                ("21min", 2.8), ("24min", 3.0)
            ]

            yellow_values = {}
            cols = st.columns(4)
            for idx, (time, default) in enumerate(time_points):
                with cols[idx % 4]:
                    yellow_values[time] = st.number_input(
                        f"{time} é»„åº¦å€¼",
                        min_value=0.0,
                        value=default,
                        step=0.1,
                        key=f"yellow_{time}"
                    )

            submitted = st.form_submit_button("ç”Ÿæˆæ¨èæ–¹æ¡ˆ")

            if submitted:
                try:
                    # æ„å»ºè¾“å…¥æ ·æœ¬ï¼ˆé¡ºåºä¸ç±»å®šä¹‰ä¸€è‡´ï¼‰
                    sample = [
                        sn_percent,    # å¯¹åº” static_cols[0]
                        add_ratio,     # å¯¹åº” static_cols[1]
                        yijia_percent, # å¯¹åº” static_cols[2]
                        yellow_values["3min"],
                        yellow_values["6min"],
                        yellow_values["9min"],
                        yellow_values["12min"],
                        yellow_values["15min"],
                        yellow_values["18min"],
                        yellow_values["21min"],
                        yellow_values["24min"]
                    ]

                    prediction = predictor.predict_one(sample)

                    # ç»“æœæ˜ å°„è¡¨
                    result_map = {
                        1: {"name": "æ— "},
                        2: {"name": "æ°¯åŒ–çŸ³èœ¡"},
                        3: {"name": "EA12ï¼ˆè„‚è‚ªé…¸å¤åˆé†‡é…¯ï¼‰"},
                        4: {"name": "EA15ï¼ˆå¸‚å”®æ¶²ä½“é’™é”Œç¨³å®šå‰‚ï¼‰"},
                        5: {"name": "EA16ï¼ˆç¯æ°§å¤§è±†æ²¹ï¼‰"},
                        6: {"name": "G70Lï¼ˆå¤šå®˜èƒ½å›¢çš„è„‚è‚ªé…¸å¤åˆé…¯æ··åˆç‰©ï¼‰"},
                        7: {"name": "EA6ï¼ˆäºšç£·é…¸é…¯ï¼‰"}
                    }

                    # æ˜¾ç¤ºæ¨èç»“æœ
                    st.success("### æ¨èç»“æœ")
                    col1, col2 = st.columns([1, 2])
                    with col1:
                        st.metric("æ¨èæ·»åŠ å‰‚ç±»å‹", result_map[prediction]["name"])
                    with col2:
                        st.markdown(f"""
                        **æ¨èæ·»åŠ å‰‚**: {result_map[prediction]["name"]}
                        """)

                except Exception as e:
                    st.error(f"é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
