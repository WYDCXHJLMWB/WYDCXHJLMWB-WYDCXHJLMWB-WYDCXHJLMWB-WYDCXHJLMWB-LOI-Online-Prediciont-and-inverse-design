import pandas as pd
import numpy as np
import warnings
from scipy import stats
from scipy.stats import kurtosis, skew
from sklearn.impute import SimpleImputer
import joblib


class Predictor:
    def __init__(self, scaler_path, svc_path):
        self.scaler = joblib.load(scaler_path)
        self.model = joblib.load(svc_path)
        
        # ç‰¹å¾åˆ—é…ç½®ï¼ˆéœ€ä¸è®­ç»ƒæ—¶ä¸¥æ ¼ä¸€è‡´ï¼‰
        self.static_cols = ["äº§å“è´¨é‡æŒ‡æ ‡_Sn%", "æ·»åŠ æ¯”ä¾‹", "ä¸€ç”²%"]
        self.time_series_cols = [
            "é»„åº¦å€¼_3min", "6min", "9min", "12min",
            "15min", "18min", "21min", "24min"
        ]
        self.eng_features = [
            'seq_length', 'max_value', 'mean_value', 'min_value',
            'std_value', 'trend', 'range_value', 'autocorr'
        ]
        self.full_cols = self.static_cols + self.time_series_cols
        self.imputer = SimpleImputer(strategy="mean")
    def _truncate(self, df):  # ç¡®ä¿ç¼©è¿›åœ¨ç±»å†…éƒ¨
        """æˆªæ–­æ—¶åºæ•°æ®çš„æ–¹æ³•"""
        time_cols = [col for col in df.columns if "min" in col.lower()]
        time_cols_ordered = [col for col in df.columns if col in time_cols]
        if time_cols_ordered:
            row = df.iloc[0][time_cols_ordered]
            if row.notna().any():
                max_idx = row.idxmax()
                max_pos = time_cols_ordered.index(max_idx)
                for col in time_cols_ordered[max_pos + 1:]:
                    df.at[df.index[0], col] = np.nan
        return df
    def _get_slope(self, row, col=None):
        # col æ˜¯å¯é€‰çš„ï¼Œå°†è¢«å¿½ç•¥
        x = np.arange(len(row))
        y = row.values
        mask = ~np.isnan(y)
        if sum(mask) >= 2:
            return stats.linregress(x[mask], y[mask])[0]
        return np.nan

    def _calc_autocorr(self, row):
        """è®¡ç®—ä¸€é˜¶è‡ªç›¸å…³ç³»æ•°"""
        values = row.dropna().values
        if len(values) > 1:
            n = len(values)
            mean = np.mean(values)
            numerator = sum((values[:-1] - mean) * (values[1:] - mean))
            denominator = sum((values - mean) ** 2)
            if denominator != 0:
                return numerator / denominator
        return np.nan
    def _extract_time_series_features(self, df):
        """ä¸¥æ ¼æŒ‰ eng_features é¡ºåºç”Ÿæˆæ—¶åºç‰¹å¾"""
        time_data = df[self.time_series_cols]
        time_data_filled = time_data.ffill(axis=1)
        
        features = pd.DataFrame()
        # æŒ‰ eng_features å®šä¹‰é¡ºåºç”Ÿæˆåˆ—
        features['seq_length'] = time_data_filled.notna().sum(axis=1)
        features['max_value'] = time_data_filled.max(axis=1)
        features['mean_value'] = time_data_filled.mean(axis=1)
        features['min_value'] = time_data_filled.min(axis=1)
        features['std_value'] = time_data_filled.std(axis=1)
        features['trend'] = time_data_filled.apply(self._get_slope, axis=1)
        features['range_value'] = features['max_value'] - features['min_value']
        features['autocorr'] = time_data_filled.apply(self._calc_autocorr, axis=1)
        
        # å¼ºåˆ¶åˆ—é¡ºåº
        return features[self.eng_features]

    def predict_one(self, sample):
        full_cols = self.static_cols + self.time_series_cols
        df = pd.DataFrame([sample], columns=full_cols)
        df = self._truncate(df)
        
        # ç‰¹å¾åˆå¹¶ï¼ˆä¸å†éœ€è¦é‡æ–°ç´¢å¼•ï¼‰
        static_features = df[self.static_cols]
        time_features = self._extract_time_series_features(df)
        feature_df = pd.concat([static_features, time_features], axis=1)
        print("è¾“å…¥æ ·æœ¬åˆ—:", df.columns.tolist())
        print("é™æ€ç‰¹å¾åˆ—:", static_features.columns.tolist())
        print("æ—¶åºç‰¹å¾åˆ—:", time_features.columns.tolist())
        print("åˆå¹¶åç‰¹å¾åˆ—:", feature_df.columns.tolist())
        print("ç¼©æ”¾å™¨æœŸæœ›åˆ—:", self.scaler.feature_names_in_.tolist())
        # ============== æ–°å¢éªŒè¯æ­¥éª¤ ==============
        expected_columns = self.static_cols + self.eng_features
        if list(feature_df.columns) != expected_columns:
            raise ValueError(
                f"ç‰¹å¾åˆ—é¡ºåºé”™è¯¯ï¼\nå½“å‰åˆ—é¡ºåºï¼š{feature_df.columns.tolist()}\n"
                f"æœŸæœ›åˆ—é¡ºåºï¼š{expected_columns}"
            )
        # ============== éªŒè¯ç»“æŸ ==============
        
        # éªŒè¯ç»´åº¦
        if feature_df.shape[1] != self.scaler.n_features_in_:
            raise ValueError(
                f"ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼å½“å‰ï¼š{feature_df.shape[1]}ï¼Œ"
                f"éœ€è¦ï¼š{self.scaler.n_features_in_}"
            )
        
        X_scaled = self.scaler.transform(feature_df)
        return self.model.predict(X_scaled)[0]

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import base64
import random
from deap import base, creator, tools, algorithms

# è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬base64
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# é¡µé¢é…ç½®
image_path = "å›¾ç‰‡1.png"
icon_base64 = image_to_base64(image_path)
st.set_page_config(
    page_title="èšä¸™çƒ¯LOIå’ŒTSæ¨¡å‹",
    layout="wide",
    page_icon=f"data:image/png;base64,{icon_base64}"
)

# é¡µé¢æ ‡é¢˜æ ·å¼
width = 200
height = int(158 * (width / 507))
st.markdown(
    f"""
    <h1 style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{icon_base64}" style="width: {width}px; height: {height}px; margin-right: 15px;" />
        é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°
    </h1>
    """, 
    unsafe_allow_html=True
)

# ä¾§è¾¹æ ä¸»å¯¼èˆª
page = st.sidebar.selectbox(
    "ğŸ”§ ä¸»åŠŸèƒ½é€‰æ‹©",
    ["é¦–é¡µ","æ€§èƒ½é¢„æµ‹", "é…æ–¹å»ºè®®"],
    key="main_nav"
)

# å­åŠŸèƒ½é€‰æ‹©ï¼ˆä»…åœ¨é…æ–¹å»ºè®®æ—¶æ˜¾ç¤ºï¼‰
sub_page = None
if page == "é…æ–¹å»ºè®®":
    sub_page = st.sidebar.selectbox(
        "ğŸ”§ å­åŠŸèƒ½é€‰æ‹©",
        ["é…æ–¹ä¼˜åŒ–", "æ·»åŠ å‰‚æ¨è"],
        key="sub_nav"
    )

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_models():
    loi_data = joblib.load("model_and_scaler_loi.pkl")
    ts_data = joblib.load("model_and_scaler_ts1.pkl")
    return {
        "loi_model": loi_data["model"],
        "loi_scaler": loi_data["scaler"],
        "ts_model": ts_data["model"],
        "ts_scaler": ts_data["scaler"],
        "loi_features": pd.read_excel("trainrg3.xlsx").drop(columns="LOI", errors='ignore').columns.tolist(),
        "ts_features": pd.read_excel("trainrg3TS.xlsx").drop(columns="TS", errors='ignore').columns.tolist(),
    }
models = load_models()

# è·å–å•ä½
def get_unit(fraction_type):
    if fraction_type == "è´¨é‡":
        return "g"
    elif fraction_type == "è´¨é‡åˆ†æ•°":
        return "wt%"
    elif fraction_type == "ä½“ç§¯åˆ†æ•°":
        return "vol%"

# ä¿è¯PPåœ¨é¦–åˆ—
def ensure_pp_first(features):
    if "PP" in features:
        features.remove("PP")
    return ["PP"] + sorted(features)

# é¦–é¡µ
if page == "é¦–é¡µ":
    st.markdown("""
    æœ¬å¹³å°åŸºäºå…ˆè¿›çš„äººå·¥æ™ºèƒ½å’Œææ–™ç§‘å­¦æŠ€æœ¯ï¼Œè‡´åŠ›äºæä¾›èšä¸™çƒ¯ï¼ˆPPï¼‰ç­‰èšåˆç‰©å¤åˆææ–™çš„æ€§èƒ½é¢„æµ‹ä¸é…æ–¹ä¼˜åŒ–å»ºè®®ã€‚
    é€šè¿‡æœ¬å¹³å°ï¼Œç”¨æˆ·å¯ä»¥è¿›è¡Œææ–™æ€§èƒ½é¢„æµ‹ï¼ˆå¦‚LOIå’ŒTSé¢„æµ‹ï¼‰ï¼Œå¹¶æ ¹æ®æ€§èƒ½ç›®æ ‡ä¼˜åŒ–é…æ–¹ï¼Œæ¨èé€‚åˆçš„åŠ©å‰‚ã€‚
    """)
    st.markdown("<hr>", unsafe_allow_html=True)  # æ·»åŠ æ°´å¹³åˆ†éš”çº¿
    # åŠŸèƒ½æ¦‚è§ˆ
    st.markdown("""
    ## åŠŸèƒ½æ¦‚è§ˆ
    1. **æ€§èƒ½é¢„æµ‹**ï¼šé€šè¿‡è¾“å…¥ææ–™é…æ–¹ï¼Œé¢„æµ‹èšåˆç‰©å¤åˆææ–™çš„LOIå’ŒTSæ€§èƒ½ã€‚
    2. **é…æ–¹å»ºè®®**ï¼šæ ¹æ®ç›®æ ‡æ€§èƒ½ï¼Œä¼˜åŒ–ææ–™é…æ–¹ã€‚
    3. **æ·»åŠ å‰‚æ¨è**ï¼šæ ¹æ®é»„åº¦å€¼ç­‰æ—¶åºæ•°æ®ï¼Œæ™ºèƒ½æ¨èæœ€ä½³æ·»åŠ å‰‚ã€‚
    """)
    st.markdown("<hr>", unsafe_allow_html=True)  # æ·»åŠ æ°´å¹³åˆ†éš”çº¿
    # å¼•ç”¨éƒ¨åˆ†
    st.markdown("""
    ## **å¼•ç”¨**
    Weibin, Ma; Ling, Li; Yu, Zhang et al. Active learning-based generative design of halogen-free flame-retardant polymeric composites. Journal of Materials Informatics
    """)

    # è‡´è°¢éƒ¨åˆ†ä¼˜åŒ–ï¼Œæ·»åŠ æ¢è¡Œç¬¦
    st.markdown("""
    ## **è‡´è°¢**<br>
    *è´¡çŒ®è€…*ï¼š<br>
    *å›¢é˜Ÿ*ï¼š<br>
    ä¸Šæµ·å¤§å­¦åŠŸèƒ½é«˜åˆ†å­ç»„<br>
    *å¼€å‘è€…*ï¼š<br>
    é©¬ç»´å®¾åšå£«ç”Ÿ<br>
    *å®¡æŸ¥*ï¼š<br>
    ä¸é¹æ•™æˆ<br>
    *åŸºé‡‘æ”¯æŒ*ï¼š<br>
    äº‘å—çœç§‘æŠ€é‡ç‚¹è®¡åˆ’é¡¹ç›® ï¼ˆ202302AB080022ï¼‰ã€è‹å·å¸‚é‡ç‚¹æŠ€æœ¯ç ”ç©¶é¡¹ç›® ï¼ˆSYG2024017ï¼‰
    """, unsafe_allow_html=True)

    # æ·»åŠ åˆ†éš”çº¿å’ŒèƒŒæ™¯è‰²
    st.markdown("<hr>", unsafe_allow_html=True)  # æ·»åŠ æ°´å¹³åˆ†éš”çº¿


# æ€§èƒ½é¢„æµ‹é¡µé¢
elif page == "æ€§èƒ½é¢„æµ‹":
    st.subheader("ğŸ”® æ€§èƒ½é¢„æµ‹ï¼šåŸºäºé…æ–¹é¢„æµ‹LOIå’ŒTS")
    
    matrix_materials = ["PP", "PA", "PC/ABS", "POM", "PBT", "PVC", "å…¶ä»–"]
    flame_retardants = [
        "AHP", "ammonium octamolybdate", "Al(OH)3", "CFA", "APP", "Pentaerythritol", "DOPO", 
        "EPFR-1100NT", "XS-FR-8310", "ZS", "XiuCheng", "ZHS", "ZnB", "antimony oxides", 
        "Mg(OH)2", "TCA", "MPP", "PAPP", "å…¶ä»–"
    ]
    additives = [
        "wollastonite", "M-2200B", "ZBS-PV-OA", "FP-250S", "silane coupling agent", "antioxidant", 
        "SiO2", "å…¶ä»–"
    ]
    
    fraction_type = st.sidebar.selectbox("é€‰æ‹©è¾“å…¥çš„å•ä½", ["è´¨é‡", "è´¨é‡åˆ†æ•°", "ä½“ç§¯åˆ†æ•°"])

    st.subheader("è¯·é€‰æ‹©é…æ–¹ä¸­çš„åŸºä½“ã€é˜»ç‡ƒå‰‚å’ŒåŠ©å‰‚")
    selected_matrix = st.selectbox("é€‰æ‹©åŸºä½“", matrix_materials, index=0)
    selected_flame_retardants = st.multiselect("é€‰æ‹©é˜»ç‡ƒå‰‚", flame_retardants, default=["ZS"])
    selected_additives = st.multiselect("é€‰æ‹©åŠ©å‰‚", additives, default=["wollastonite"])
    
    input_values = {}
    unit_matrix = get_unit(fraction_type)
    unit_flame_retardant = get_unit(fraction_type)
    unit_additive = get_unit(fraction_type)
    
    input_values[selected_matrix] = st.number_input(f"é€‰æ‹© {selected_matrix} ({unit_matrix})", min_value=0.0, max_value=100.0, value=50.0, step=0.1)
    
    for fr in selected_flame_retardants:
        input_values[fr] = st.number_input(f"é€‰æ‹© {fr}({unit_flame_retardant})", min_value=0.0, max_value=100.0, value=10.0, step=0.1)
    
    for ad in selected_additives:
        input_values[ad] = st.number_input(f"é€‰æ‹© {ad}  ({unit_additive})", min_value=0.0, max_value=100.0, value=10.0, step=0.1)
    
    total = sum(input_values.values())
    is_only_pp = all(v == 0 for k, v in input_values.items() if k != "PP")
    
    with st.expander("âœ… è¾“å…¥éªŒè¯"):
        if fraction_type == "ä½“ç§¯åˆ†æ•°":
            if abs(total - 100.0) > 1e-6:
                st.error(f"â— ä½“ç§¯åˆ†æ•°çš„æ€»å’Œå¿…é¡»ä¸º100%ï¼ˆå½“å‰ï¼š{total:.2f}%ï¼‰")
            else:
                st.success("ä½“ç§¯åˆ†æ•°æ€»å’ŒéªŒè¯é€šè¿‡")
        elif fraction_type == "è´¨é‡åˆ†æ•°":
            if abs(total - 100.0) > 1e-6:
                st.error(f"â— è´¨é‡åˆ†æ•°çš„æ€»å’Œå¿…é¡»ä¸º100%ï¼ˆå½“å‰ï¼š{total:.2f}%ï¼‰")
            else:
                st.success("è´¨é‡åˆ†æ•°æ€»å’ŒéªŒè¯é€šè¿‡")
        else:
            st.success("æˆåˆ†æ€»å’ŒéªŒè¯é€šè¿‡")
            if is_only_pp:
                st.info("æ£€æµ‹åˆ°çº¯PPé…æ–¹")

    if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
        if fraction_type in ["ä½“ç§¯åˆ†æ•°", "è´¨é‡åˆ†æ•°"] and abs(total - 100.0) > 1e-6:
            st.error(f"é¢„æµ‹ä¸­æ­¢ï¼š{fraction_type}çš„æ€»å’Œå¿…é¡»ä¸º100%")
            st.stop()

        if is_only_pp:
            loi_pred = 17.5
            ts_pred = 35.0
        else:
            if fraction_type == "ä½“ç§¯åˆ†æ•°":
                vol_values = np.array(list(input_values.values()))
                mass_values = vol_values
                total_mass = mass_values.sum()
                input_values = {k: (v / total_mass * 100) for k, v in zip(input_values.keys(), mass_values)}
            
            for feature in models["loi_features"]:
                if feature not in input_values:
                    input_values[feature] = 0.0

            loi_input = np.array([[input_values[f] for f in models["loi_features"]]])
            loi_scaled = models["loi_scaler"].transform(loi_input)
            loi_pred = models["loi_model"].predict(loi_scaled)[0]
        
            for feature in models["ts_features"]:
                if feature not in input_values:
                    input_values[feature] = 0.0

            ts_input = np.array([[input_values[f] for f in models["ts_features"]]])
            ts_scaled = models["ts_scaler"].transform(ts_input)
            ts_pred = models["ts_model"].predict(ts_scaled)[0]
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric(label="LOIé¢„æµ‹å€¼", value=f"{loi_pred:.2f}%")
        with col2:
            st.metric(label="TSé¢„æµ‹å€¼", value=f"{ts_pred:.2f} MPa")

# é…æ–¹å»ºè®®é¡µé¢
elif page == "é…æ–¹å»ºè®®":
    if sub_page == "é…æ–¹ä¼˜åŒ–":
        fraction_type = st.sidebar.radio(
            "ğŸ“ å•ä½ç±»å‹",
            ["è´¨é‡", "è´¨é‡åˆ†æ•°", "ä½“ç§¯åˆ†æ•°"],
            key="unit_type"
        )
        st.subheader("ğŸ§ª é…æ–¹å»ºè®®ï¼šæ ¹æ®æ€§èƒ½åæ¨é…æ–¹")
    
        col1, col2 = st.columns(2)
        with col1:
            target_loi = st.number_input("ç›®æ ‡LOIå€¼ï¼ˆ%ï¼‰", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
        with col2:
            target_ts = st.number_input("ç›®æ ‡TSå€¼ï¼ˆMPaï¼‰", min_value=10.0, max_value=100.0, value=50.0, step=0.1)
        
        with st.expander("âš™ï¸ ç®—æ³•å‚æ•°è®¾ç½®"):
            pop_size = st.number_input("ç§ç¾¤æ•°é‡", 50, 500, 200)
            n_gen = st.number_input("è¿­ä»£ä»£æ•°", 10, 100, 50)
            cx_prob = st.slider("äº¤å‰æ¦‚ç‡", 0.1, 1.0, 0.7)
            mut_prob = st.slider("å˜å¼‚æ¦‚ç‡", 0.1, 1.0, 0.2)
    
        if st.button("ğŸ” å¼€å§‹ä¼˜åŒ–", type="primary"):
            creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
            creator.create("Individual", list, fitness=creator.FitnessMin)
            
            toolbox = base.Toolbox()
            all_features = ensure_pp_first(list(set(models["loi_features"] + models["ts_features"])))
            n_features = len(all_features)
            
            def generate_individual():
                individual = [random.uniform(0, 100) for _ in range(n_features)]
                total = sum(individual)
                return [max(0, x / total * 100) for x in individual]
            
            toolbox.register("individual", tools.initIterate, creator.Individual, generate_individual)
            toolbox.register("population", tools.initRepeat, list, toolbox.individual)
            
            def evaluate(individual):
                if fraction_type == "ä½“ç§¯åˆ†æ•°":
                    vol_values = np.array(individual)
                    mass_values = vol_values
                    total_mass = mass_values.sum()
                    if total_mass == 0:
                        return (1e6,)
                    mass_percent = (mass_values / total_mass) * 100
                else:
                    total = sum(individual)
                    if total == 0:
                        return (1e6,)
                    mass_percent = np.array(individual) / total * 100
                
                pp_index = all_features.index("PP")
                pp_content = mass_percent[pp_index]
                if pp_content < 50:
                    return (1e6,)
                
                loi_input = mass_percent[:len(models["loi_features"])]
                loi_scaled = models["loi_scaler"].transform([loi_input])
                loi_pred = models["loi_model"].predict(loi_scaled)[0]
                loi_error = abs(target_loi - loi_pred)
                
                ts_input = mass_percent[:len(models["ts_features"])]
                ts_scaled = models["ts_scaler"].transform([ts_input])
                ts_pred = models["ts_model"].predict(ts_scaled)[0]
                ts_error = abs(target_ts - ts_pred)
                total = sum(mass_percent)
                if abs(total - 100) > 1e-6:
                    return (1e6,)
                return (loi_error + ts_error,)
            
            toolbox.register("mate", tools.cxBlend, alpha=0.5)
            toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)
            toolbox.register("select", tools.selTournament, tournsize=3)
            toolbox.register("evaluate", evaluate)
            
            population = toolbox.population(n=pop_size)
            algorithms.eaSimple(population, toolbox, cxpb=cx_prob, mutpb=mut_prob, ngen=n_gen, verbose=False)
            
            best_individuals = tools.selBest(population, 10)
            best_values = []
            for individual in best_individuals:
                total = sum(individual)
                best_values.append([round(max(0, i / total * 100), 2) for i in individual])  # ä¿®æ­£æ‹¬å·é—­åˆ
            
            result_df = pd.DataFrame(best_values, columns=all_features)
            units = [get_unit(fraction_type) for _ in all_features]
            result_df.columns = [f"{col} ({unit})" for col, unit in zip(result_df.columns, units)]
            st.write(result_df)
    
    elif sub_page == "æ·»åŠ å‰‚æ¨è":
        st.subheader("ğŸ§ª PVCæ·»åŠ å‰‚æ™ºèƒ½æ¨è")
        predictor = Predictor("scaler_fold_1.pkl", "svc_fold_1.pkl")
        
        with st.form("additive_form"):
            st.markdown("### åŸºç¡€å‚æ•°")
            col_static = st.columns(3)
            with col_static[0]:
                add_ratio = st.number_input(
                    "äº§å“è´¨é‡æŒ‡æ ‡_Sn%", 
                    min_value=0.0,
                    max_value=100.0,
                    value=5.0,
                    step=0.1
                )
            with col_static[1]:
                sn_percent = st.number_input(
                    "æ·»åŠ æ¯”ä¾‹", 
                    min_value=0.0, 
                    max_value=100.0,
                    value=14.0,
                    step=0.1,
                    #help="é”¡å«é‡èŒƒå›´0%~19%"
                )
            with col_static[2]:
                yijia_percent = st.number_input(
                    "ä¸€ç”²%",
                    min_value=0.0,
                    max_value=100.0,
                    value=23.55,
                    step=0.1,
                    #help="ä¸€ç”²å«é‡èŒƒå›´15.1%~32%"
                )
            
            st.markdown("### æ—¶åºå‚æ•°ï¼ˆé»„åº¦å€¼éšæ—¶é—´å˜åŒ–ï¼‰")
            time_points = [
                ("3min", 15.0), ("6min", 16.0), ("9min", 17.0),
                ("12min", 18.0), ("15min", 19.0), ("18min", 20.0),
                ("21min", 21.0), ("24min", 22.0)
            ]
            yellow_values = {}
            prev_value = 5.0  # åˆå§‹æœ€å°å€¼
            cols = st.columns(4)
            
            for idx, (time, default) in enumerate(time_points):
                with cols[idx % 4]:
                    if time == "3min":
                        current = st.number_input(
                            f"{time} é»„åº¦å€¼", 
                            min_value=5.0,
                            max_value=25.0,
                            value=default,
                            step=0.1,
                            key=f"yellow_{time}"
                        )
                    else:
                        current = st.number_input(
                            f"{time} é»„åº¦å€¼",
                            min_value=prev_value,
                            value=default,
                            step=0.1,
                            key=f"yellow_{time}"
                        )
                    yellow_values[time] = current
                    prev_value = current
    
            submit_btn = st.form_submit_button("ç”Ÿæˆæ¨èæ–¹æ¡ˆ")
    
        if submit_btn:
            # æ—¶åºæ•°æ®éªŒè¯
            time_sequence = [yellow_values[t] for t, _ in time_points]
            if any(time_sequence[i] > time_sequence[i+1] for i in range(len(time_sequence)-1)):
                st.error("é”™è¯¯ï¼šé»„åº¦å€¼å¿…é¡»éšæ—¶é—´é€’å¢ï¼è¯·æ£€æŸ¥è¾“å…¥æ•°æ®")
                st.stop()
                
            try:
                sample = [
                    sn_percent, add_ratio, yijia_percent,
                    yellow_values["3min"], yellow_values["6min"],
                    yellow_values["9min"], yellow_values["12min"],
                    yellow_values["15min"], yellow_values["18min"],
                    yellow_values["21min"], yellow_values["24min"]
                ]
                prediction = predictor.predict_one(sample)
                result_map = {
                    1: "æ— æ¨èæ·»åŠ å‰‚", 
                    2: "æ°¯åŒ–çŸ³èœ¡", 
                    3: "EA12ï¼ˆè„‚è‚ªé…¸å¤åˆé†‡é…¯ï¼‰",
                    4: "EA15ï¼ˆå¸‚å”®æ¶²ä½“é’™é”Œç¨³å®šå‰‚ï¼‰", 
                    5: "EA16ï¼ˆç¯æ°§å¤§è±†æ²¹ï¼‰",
                    6: "G70Lï¼ˆå¤šå®˜èƒ½å›¢çš„è„‚è‚ªé…¸å¤åˆé…¯æ··åˆç‰©ï¼‰", 
                    7: "EA6ï¼ˆäºšç£·é…¸é…¯ï¼‰"
                }
                
                # ============== ä¿®æ”¹åçš„ç¨³å®šå‰‚æ˜¾ç¤ºéƒ¨åˆ† ==============
                additive_amount = 0.0 if prediction == 1 else add_ratio
                additive_name = result_map[prediction]
    
                # æ„å»ºå®Œæ•´é…æ–¹è¡¨
                formula_data = [
                    ["PVCä»½æ•°", 100.00],
                    ["åŠ å·¥åŠ©å‰‚ACRä»½æ•°", 1.00],
                    ["å¤–æ»‘å‰‚70Sä»½æ•°", 0.35],
                    ["MBSä»½æ•°", 5.00],
                    ["316Aä»½æ•°", 0.20],
                    ["ç¨³å®šå‰‚ç»„æˆ", ""],  # ä¸»æ ‡é¢˜
                    ["  ä»½æ•°", 1.00],
                    ["  ä¸€ç”²%", yijia_percent],
                    ["  Sn%", sn_percent],
                ]
    
                # åŠ¨æ€æ·»åŠ æ·»åŠ å‰‚ä¿¡æ¯
                if prediction != 1:
                    formula_data.extend([
                        ["  æ·»åŠ å‰‚ç±»å‹", additive_name],
                        ["  å«é‡ï¼ˆwt%ï¼‰", additive_amount]
                    ])
                else:
                    formula_data.append(["  æ¨èæ·»åŠ å‰‚", "æ— "])
    
                # åˆ›å»ºæ ¼å¼åŒ–è¡¨æ ¼
                df = pd.DataFrame(formula_data, columns=["ææ–™åç§°", "å«é‡"])
                styled_df = df.style.format({"å«é‡": "{:.2f}"})\
                                  .hide(axis="index")\
                                  .set_properties(**{
                                      'text-align': 'left',
                                      'font-size': '14px'
                                  })\
                                  .set_properties(
                                      subset=df.index[df['ææ–™åç§°'].str.startswith('  ')],
                                      **{'padding-left': '30px', 'color': '#2c3e50'}
                                  )
    
                # åŒåˆ—å¸ƒå±€å±•ç¤º
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.success(f"**æ¨èç»“æœ**\n\n{additive_name}")
                    st.metric(
                        "å»ºè®®æ·»åŠ é‡", 
                        f"{additive_amount:.2f}%",
                        delta="æ— æ·»åŠ " if prediction == 1 else None,
                        delta_color="off"
                    )
                    
                with col2:
                    st.markdown("**å®Œæ•´é…æ–¹è¡¨ï¼ˆåŸºäºPVC 100ä»½ï¼‰**")
                    st.dataframe(
                        styled_df,
                        use_container_width=True,
                        height=320,
                        column_config={
                            "ææ–™åç§°": st.column_config.Column(
                                width="medium",
                                help="é…æ–¹ç»„æˆæ˜ç»†"
                            ),
                            "å«é‡": st.column_config.NumberColumn(
                                format="%.2f",
                                width="small"
                            )
                        }
                    )
                # ============== ä¿®æ”¹ç»“æŸ ==============
                
            except Exception as e:
                st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
                st.stop()
# æ·»åŠ é¡µè„š
def add_footer():
    st.markdown("""
    <hr>
    <footer style="text-align: center;">
        <p>Â© 2025 é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°</p>
        <p>å¼€å‘è€…: é©¬ç»´å®¾</p>
        <p>å¹³å°æ€§è´¨å£°æ˜ï¼šæœ¬å¹³å°ä¸ºç§‘ç ”åä½œç½‘ç»œæœåŠ¡å¹³å°ï¼Œæ‰€æœ‰å†…å®¹ä»…ä¾›å­¦æœ¯ç ”ç©¶ã€æŠ€æœ¯éªŒè¯ç­‰éè¥åˆ©æ€§ç§‘ç ”æ´»åŠ¨ä½¿ç”¨ï¼Œä¸¥ç¦ç”¨äºä»»ä½•å•†ä¸šç”¨é€”ã€‚</p>
    </footer>
    """, unsafe_allow_html=True)

add_footer() 
