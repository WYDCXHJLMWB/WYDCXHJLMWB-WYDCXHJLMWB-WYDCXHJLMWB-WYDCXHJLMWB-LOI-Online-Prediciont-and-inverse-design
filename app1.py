import streamlit as st
import pandas as pd
import numpy as np
import joblib
from hyperopt import hp, fmin, tpe, STATUS_OK, Trials
from sklearn.preprocessing import StandardScaler
from PIL import Image
import base64

# Function to convert image to base64
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# è®¾ç½®é¡µé¢é…ç½®ï¼ˆä¿æŒåŸæ ·ï¼Œå›¾æ ‡ä¾ç„¶æ˜¯æ˜¾ç¤ºåœ¨æµè§ˆå™¨æ ‡ç­¾é¡µä¸­ï¼‰
image_path = "å›¾ç‰‡1.png"  # ä½¿ç”¨ä¸Šä¼ çš„å›¾ç‰‡è·¯å¾„
icon_base64 = image_to_base64(image_path)  # è½¬æ¢ä¸º base64

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(page_title="èšä¸™çƒ¯LOIæ¨¡å‹", layout="wide", page_icon=f"data:image/png;base64,{icon_base64}")

# å›¾æ ‡åŸå§‹å°ºå¯¸ï¼š507x158ï¼Œè®¡ç®—å‡ºæ¯”ä¾‹
width = 200  # è®¾ç½®å›¾æ ‡çš„å®½åº¦ä¸º100px
height = int(158 * (width / 507))  # è®¡ç®—ä¿æŒæ¯”ä¾‹åçš„é«˜åº¦

# åœ¨é¡µé¢ä¸Šæ’å…¥å›¾æ ‡ä¸æ ‡é¢˜
st.markdown(
    f"""
    <h1 style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{icon_base64}" style="width: {width}px; height: {height}px; margin-right: 15px;" />
        é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°
    </h1>
    """, 
    unsafe_allow_html=True
)

page = st.sidebar.selectbox("ğŸ”§ é€‰æ‹©åŠŸèƒ½", ["æ€§èƒ½é¢„æµ‹", "é…æ–¹å»ºè®®"])

# åŠ è½½æ¨¡å‹ä¸ç¼©æ”¾å™¨
data = joblib.load("model_and_scaler_loi.pkl")
model = data["model"]
scaler = data["scaler"]

df = pd.read_excel("trainrg3.xlsx")
feature_names = df.columns.tolist()
if "LOI" in feature_names:
    feature_names.remove("LOI")

unit_type = st.radio("ğŸ“ è¯·é€‰æ‹©é…æ–¹è¾“å…¥å•ä½", ["è´¨é‡ (g)", "è´¨é‡åˆ†æ•° (wt%)", "ä½“ç§¯åˆ†æ•° (vol%)"], horizontal=True)

if page == "æ€§èƒ½é¢„æµ‹":
    st.subheader("ğŸ”¬ æ­£å‘é¢„æµ‹ï¼šé…æ–¹ â†’ LOI")

    with st.form("input_form"):
        user_input = {}
        total = 0
        cols = st.columns(3)
        for i, name in enumerate(feature_names):
            unit_label = {
                "è´¨é‡ (g)": "g",
                "è´¨é‡åˆ†æ•° (wt%)": "wt%",
                "ä½“ç§¯åˆ†æ•° (vol%)": "vol%"
            }[unit_type]
            val = cols[i % 3].number_input(f"{name} ({unit_label})", value=0.0, step=0.1 if "è´¨é‡" in unit_type else 0.01)
            user_input[name] = val
            total += val

        submitted = st.form_submit_button("ğŸ“Š å¼€å§‹é¢„æµ‹")

    if submitted:
        # åˆ¤æ–­æ€»å’Œæ˜¯å¦æ»¡è¶³ä¸º100
        if unit_type != "è´¨é‡ (g)" and abs(total - 100) > 1e-3:
            st.warning("âš ï¸ é…æ–¹åŠ å’Œä¸ä¸º100ï¼Œæ— æ³•é¢„æµ‹ã€‚è¯·ç¡®ä¿æ€»å’Œä¸º100åå†è¿›è¡Œé¢„æµ‹ã€‚")
        else:
            # è‹¥æ˜¯åˆ†æ•°å•ä½ï¼Œåˆ™å†å½’ä¸€åŒ–ä¸€é
            if unit_type == "è´¨é‡ (g)" and total > 0:  # åˆ¤æ–­æ˜¯å¦ä¸ºè´¨é‡å•ä½
                # å°†æ¯ä¸ªæˆåˆ†çš„è´¨é‡è½¬æ¢ä¸ºè´¨é‡åˆ†æ•°
                user_input = {k: (v / total) * 100 for k, v in user_input.items()}  # å½’ä¸€åŒ–ä¸ºè´¨é‡åˆ†æ•°

            elif unit_type != "è´¨é‡ (g)" and total > 0:
                user_input = {k: v / total * 100 for k, v in user_input.items()}  # ç¡®ä¿æ€»å’Œä¸º100

            # æ£€æŸ¥æ˜¯å¦ä»…è¾“å…¥äº†PPï¼Œå¹¶ä¸”PPä¸º100
            if np.all([user_input.get(name, 0) == 0 for name in feature_names if name != "PP"]) and user_input.get("PP", 0) == 100:
                # å¦‚æœåªè¾“å…¥äº†PPä¸”PPä¸º100ï¼Œå¼ºåˆ¶è¿”å›LOI=17.5
                st.markdown("### ğŸ¯ é¢„æµ‹ç»“æœ")
                st.metric(label="æé™æ°§æŒ‡æ•° (LOI)", value="17.5 %")
            else:
                input_array = np.array([list(user_input.values())])
                input_scaled = scaler.transform(input_array)
                prediction = model.predict(input_scaled)[0]

                st.markdown("### ğŸ¯ é¢„æµ‹ç»“æœ")
                st.metric(label="æé™æ°§æŒ‡æ•° (LOI)", value=f"{prediction:.2f} %")

elif page == "é€†å‘è®¾è®¡":

    target_loi = st.number_input("ğŸ¯ è¯·è¾“å…¥ç›®æ ‡ LOI å€¼ (%)", value=50.0, step=0.1)

    if st.button("ğŸ”„ å¼€å§‹é€†å‘è®¾è®¡"):
        with st.spinner("æ­£åœ¨åæ¨å‡ºæœ€ä¼˜é…æ–¹ï¼Œè¯·ç¨å€™..."):

            # é…æ–¹èŒƒå›´
            bounds = {
                feature: (0, 100) for feature in feature_names
            }
            pp_index = feature_names.index("PP")
            bounds["PP"] = (50, 100)  # è®¾å®šPPçš„èŒƒå›´æ›´é«˜ä¸€äº›

            # ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–é¢„æµ‹ LOI ä¸ç›®æ ‡ LOI ä¹‹é—´çš„å·®å¼‚
            def objective(params):
                # å°†å‚æ•°å½’ä¸€åŒ–ï¼Œä½¿æ€»å’Œä¸º100
                params_norm = np.array(params) / sum(params) * 100
                params_norm = params_norm.round(3)
                
                # æ ‡å‡†åŒ–è¾“å…¥å¹¶é¢„æµ‹
                params_scaled = scaler.transform([params_norm])
                prediction = model.predict(params_scaled)[0]

                # è¿”å›è¯¯å·®
                return abs(prediction - target_loi)

            # é…æ–¹æœç´¢ç©ºé—´
            space = [hp.uniform(feature, bounds[feature][0], bounds[feature][1]) for feature in feature_names]
            
            # è¿è¡ŒHyperoptä¼˜åŒ–
            trials = Trials()
            best = fmin(
                fn=objective,
                space=space,
                algo=tpe.suggest,
                max_evals=100,
                trials=trials
            )
            
            # æ˜¾ç¤ºç»“æœ
            best_params = np.array([best[feature] for feature in feature_names])
            best_params_norm = best_params / sum(best_params) * 100
            best_prediction = model.predict(scaler.transform([best_params_norm]))[0]

            st.success("ğŸ‰ æˆåŠŸåæ¨é…æ–¹ï¼")
            st.metric("é¢„æµ‹ LOI", f"{best_prediction:.2f} %")

            # æ˜¾ç¤ºæœ€ä¼˜é…æ–¹
            df_result = pd.DataFrame([best_params_norm], columns=feature_names)
            df_result.columns = [f"{col} (wt%)" for col in df_result.columns]

            st.markdown("### ğŸ“‹ æœ€ä¼˜é…æ–¹å‚æ•°")
            st.dataframe(df_result.round(2))

