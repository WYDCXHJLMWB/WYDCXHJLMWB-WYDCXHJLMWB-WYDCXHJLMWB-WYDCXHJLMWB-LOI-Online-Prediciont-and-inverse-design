import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
from deap import base, creator, tools, algorithms
import random
import base64

# è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬base64
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# é¡µé¢é…ç½®
image_path = "å›¾ç‰‡1.png"
icon_base64 = image_to_base64(image_path)
st.set_page_config(
    page_title="èšä¸™çƒ¯LOIæ¨¡å‹",
    layout="wide",
    page_icon=f"data:image/png;base64,{icon_base64}"
)

# é¡µé¢æ ‡é¢˜æ ·å¼
width = 200
height = int(158 * (width / 507))
st.markdown(
    f"""
    <h1 style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{icon_base64}" style="width: {width}px; height: {height}px; margin-right: 15px;" />
        é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°
    </h1>
    """, 
    unsafe_allow_html=True
)

# ä¾§è¾¹æ å¯¼èˆª
page = st.sidebar.selectbox("ğŸ”§ é€‰æ‹©åŠŸèƒ½", ["æ€§èƒ½é¢„æµ‹", "é…æ–¹å»ºè®®"])

# åŠ è½½æ¨¡å‹å’Œæ•°æ®
data = joblib.load("model_and_scaler_loi.pkl")
model = data["model"]
scaler = data["scaler"]
df = pd.read_excel("trainrg3.xlsx")
feature_names = df.columns.tolist()
if "LOI" in feature_names:
    feature_names.remove("LOI")

# å•ä½ç±»å‹å¤„ç†
unit_type = st.radio("ğŸ“ è¯·é€‰æ‹©é…æ–¹è¾“å…¥å•ä½", ["è´¨é‡ (g)", "è´¨é‡åˆ†æ•° (wt%)", "ä½“ç§¯åˆ†æ•° (vol%)"], horizontal=True)

# æ€§èƒ½é¢„æµ‹é¡µé¢
if page == "æ€§èƒ½é¢„æµ‹":
    st.subheader("ğŸ”¬ æ­£å‘é¢„æµ‹ï¼šé…æ–¹ â†’ LOI")
    
    with st.form("input_form"):
        user_input = {}
        total = 0
        cols = st.columns(3)
        for i, name in enumerate(feature_names):
            unit_label = {
                "è´¨é‡ (g)": "g",
                "è´¨é‡åˆ†æ•° (wt%)": "wt%",
                "ä½“ç§¯åˆ†æ•° (vol%)": "vol%"
            }[unit_type]
            val = cols[i%3].number_input(
                f"{name} ({unit_label})", 
                value=0.0, 
                step=0.1 if "è´¨é‡" in unit_type else 0.01
            )
            user_input[name] = val
            total += val

        submitted = st.form_submit_button("ğŸ“Š å¼€å§‹é¢„æµ‹")

    if submitted:
        if unit_type != "è´¨é‡ (g)" and abs(total - 100) > 1e-3:
            st.warning("âš ï¸ é…æ–¹åŠ å’Œä¸ä¸º100ï¼Œæ— æ³•é¢„æµ‹ã€‚è¯·ç¡®ä¿æ€»å’Œä¸º100åå†è¿›è¡Œé¢„æµ‹ã€‚")
        else:
            # å•ä½è½¬æ¢é€»è¾‘
            if unit_type == "è´¨é‡ (g)" and total > 0:
                user_input = {k: (v/total)*100 for k,v in user_input.items()}
            # ä½“ç§¯åˆ†æ•°è®¡ç®—é€»è¾‘ï¼ˆåŸºäºè´¨é‡åˆ†æ•°æ¯”ä¾‹ï¼‰
            elif unit_type == "è´¨é‡åˆ†æ•° (wt%)":
                total_weight = sum(user_input.values())
                user_input = {k: (v/total_weight)*100 for k,v in user_input.items()}
            elif unit_type == "ä½“ç§¯åˆ†æ•° (vol%)":
                total_weight = sum(user_input.values())
                user_input = {k: (v/total_weight)*100 for k,v in user_input.items()}


            # é¢„æµ‹é€»è¾‘
            if all(v==0 for k,v in user_input.items() if k!="PP") and user_input.get("PP",0)==100:
                st.metric("æé™æ°§æŒ‡æ•° (LOI)", "17.5%")
            else:
                input_array = np.array([list(user_input.values())])
                input_scaled = scaler.transform(input_array)
                prediction = model.predict(input_scaled)[0]
                st.metric("æé™æ°§æŒ‡æ•° (LOI)", f"{prediction:.2f}%")

elif page == "é…æ–¹å»ºè®®":
    st.subheader("ğŸ§ª é…æ–¹å»ºè®®ï¼šæ ¹æ®æ€§èƒ½åæ¨é…æ–¹")
    target_loi = st.number_input("ç›®æ ‡LOIå€¼", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
    
    # ä¿®å¤1ï¼šç¡®ä¿DEAP creatoråªåˆ›å»ºä¸€æ¬¡
    if 'FitnessMin' not in creator.__dict__:
        creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
    if 'Individual' not in creator.__dict__:
        creator.create("Individual", list, fitness=creator.FitnessMin)
    
    # é—ä¼ ç®—æ³•é…ç½®
    toolbox = base.Toolbox()
    toolbox.register("attr_float", random.uniform, 0.01, 50)
    toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, n=len(feature_names))
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)
    
    def evaluate(individual):
        # å¼ºåˆ¶PPå«é‡æ˜¯æœ€å¤§å€¼
        pp_index = feature_names.index("PP")  # åŠ¨æ€è·å–PPçš„ç´¢å¼•ä½ç½®
        if individual[pp_index] != max(individual):
            return (1000,)  # å¦‚æœPPä¸æ˜¯æœ€å¤§å€¼ï¼Œè¿”å›ä¸€ä¸ªå¤§å€¼ï¼Œä¿è¯ä¸é€‰æ‹©è¿™ä¸ªä¸ªä½“
    
        # å½’ä¸€åŒ–å¤„ç†
        total = sum(individual)
        if total == 0:  # å¦‚æœæ€»å’Œä¸º0ï¼Œè¿”å›ä¸€ä¸ªé”™è¯¯å€¼ï¼Œé˜²æ­¢é™¤é›¶
            return (1000,)
    
        normalized = [x/total*100 for x in individual]
    
        # è°ƒè¯•è¾“å‡ºï¼ŒæŸ¥çœ‹individualå’Œå½’ä¸€åŒ–åçš„ç»“æœ
        print(f"Individual: {individual}")
        print(f"Normalized: {normalized}")
    
        # é¢„æµ‹LOI
        input_array = np.array([normalized])
        input_scaled = scaler.transform(input_array)
        predicted = model.predict(input_scaled)[0]
    
        # è°ƒè¯•è¾“å‡ºï¼ŒæŸ¥çœ‹é¢„æµ‹ç»“æœ
        print(f"Predicted LOI: {predicted}")
    
        return (abs(predicted - target_loi),)  # è¿”å›ç›®æ ‡LOIçš„è¯¯å·®


    
    # é—ä¼ ç®—æ³•æ“ä½œé…ç½®
    toolbox.register("mate", tools.cxBlend, alpha=0.5)
    toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=5, indpb=0.2)
    toolbox.register("select", tools.selTournament, tournsize=3)
    toolbox.register("evaluate", evaluate)
    
    if st.button("ç”Ÿæˆæ¨èé…æ–¹"):
        with st.spinner("ğŸ” æ­£åœ¨ä¼˜åŒ–é…æ–¹..."):
            # åˆå§‹åŒ–hof
            hof = tools.HallOfFame(1)  # ä¿®å¤3ï¼šæ­£ç¡®å®šä¹‰hof
            
            # ç®—æ³•å‚æ•°
            POP_SIZE = 100
            GEN_NUM = 50
            CXPB = 0.7
            MUTPB = 0.3
            
            pop = toolbox.population(n=POP_SIZE)
            stats = tools.Statistics(lambda ind: ind.fitness.values)
            stats.register("avg", np.mean)
            stats.register("min", np.min)
            
            # ä½¿ç”¨DEAPå†…ç½®ç®—æ³•ç®€åŒ–æµç¨‹
            algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=GEN_NUM, 
                               stats=stats, halloffame=hof, verbose=False)
            
            # è·å–æœ€ä½³ä¸ªä½“å¹¶å¤„ç†å•ä½
            best = hof[0]  # ç°åœ¨hofå·²æ­£ç¡®å®šä¹‰
            total = sum(best)
            recipe_wt = {name: (val/total)*100 for name, val in zip(feature_names, best)}
            
            # æ ¹æ®å•ä½ç±»å‹è½¬æ¢æ•°å€¼å’Œå•ä½æ ‡ç­¾
            if unit_type == "è´¨é‡ (g)":
                recipe = recipe_wt  # æ•°å€¼ç›´æ¥æ˜¾ç¤ºä¸ºå…‹æ•°ï¼ˆå‡è®¾æ€»è´¨é‡100gï¼‰
                unit_label = "g"
            elif unit_type == "è´¨é‡åˆ†æ•° (wt%)":
                recipe = recipe_wt
                unit_label = "wt%"
            elif unit_type == "ä½“ç§¯åˆ†æ•° (vol%)":
                recipe = recipe_wt  # å‡è®¾ä½“ç§¯åˆ†æ•°ä¸è´¨é‡åˆ†æ•°æ•°å€¼ç›¸åŒ
                unit_label = "vol%"

            # æ·»åŠ å•ä½åˆ°åˆ—å
            columns_with_units = [f"{name} ({unit_label})" for name in feature_names]
            
            # åˆ›å»ºç»“æœDataFrame
            recipe_df = pd.DataFrame([recipe]*10, columns=columns_with_units)
            recipe_df.index = [f"é…æ–¹ {i+1}" for i in range(10)]

            # éªŒè¯PPå«é‡
            pp_col = f"PP ({unit_label})"
            for i in range(10):
                # ç¡®ä¿PPæ˜¯æœ€å¤§å€¼ä¸”â‰¥50%
                recipe_df.loc[f"é…æ–¹ {i+1}", pp_col] = max(recipe_df.loc[f"é…æ–¹ {i+1}"])
                if recipe_df.loc[f"é…æ–¹ {i+1}", pp_col] < 50:
                    recipe_df.loc[f"é…æ–¹ {i+1}", pp_col] = 50

            st.success("âœ… é…æ–¹ä¼˜åŒ–å®Œæˆï¼")
            
            st.subheader("æ¨èé…æ–¹åˆ—è¡¨")
            st.dataframe(recipe_df.style.format("{:.2f}"))

            # æ˜¾ç¤ºé¢„æµ‹å€¼ï¼ˆä¿æŒä¸å˜ï¼‰
            input_array = np.array([[recipe_wt[name] for name in feature_names]])
            input_scaled = scaler.transform(input_array)
            predicted_loi = model.predict(input_scaled)[0]
            st.metric("é¢„æµ‹LOI", f"{predicted_loi:.2f}%")
