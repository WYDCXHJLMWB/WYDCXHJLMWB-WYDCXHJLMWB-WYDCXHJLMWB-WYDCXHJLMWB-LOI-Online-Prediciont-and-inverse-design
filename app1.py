import pandas as pd
import numpy as np
import warnings
from scipy import stats
from scipy.stats import kurtosis, skew
from sklearn.impute import SimpleImputer
import joblib


import pandas as pd
import numpy as np
import joblib
from scipy import stats
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings("ignore")

class Predictor:
    def __init__(self, scaler_path, svc_path):
        self.scaler = joblib.load(scaler_path)
        self.model = joblib.load(svc_path)
        
        # ç‰¹å¾ç»“æ„å®šä¹‰
        self.static_cols = ["äº§å“è´¨é‡æŒ‡æ ‡_Sn%", "æ·»åŠ æ¯”ä¾‹", "ä¸€ç”²%"]
        self.time_series_cols = ["3min", "6min", "9min", "12min", "15min", "18min", "21min", "24min"]
        self.eng_features = ['seq_length', 'max_value', 'mean_value', 'min_value', 'std_value', 'trend', 'range_value', 'autocorr']
        self.expected_columns = self.static_cols + self.eng_features
        self.full_cols = self.static_cols + self.time_series_cols
        
        # åˆå§‹åŒ–éªŒè¯
        self._validate_components()

    def _validate_components(self):
        """æ ¸å¿ƒéªŒè¯æ–¹æ³•"""
        # ================= ç‰¹å¾ç»´åº¦éªŒè¯ =================
        # è·å–æ ‡å‡†åŒ–å™¨å’Œæ¨¡å‹çš„ç‰¹å¾ç»´åº¦
        scaler_features = getattr(self.scaler, "n_features_in_", None)
        model_features = getattr(self.model, "n_features_in_", None)
        
        # è·å–å½“å‰ä»£ç çš„ç‰¹å¾ç»´åº¦
        code_features = len(self.expected_columns)
        
        error_msgs = []
        if scaler_features != code_features:
            error_msgs.append(
                f"æ ‡å‡†åŒ–å™¨ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼ä»£ç : {code_features}ï¼Œæ ‡å‡†åŒ–å™¨: {scaler_features}"
            )
        if model_features and model_features != code_features:
            error_msgs.append(
                f"æ¨¡å‹ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼ä»£ç : {code_features}ï¼Œæ¨¡å‹: {model_features}"
            )
        if error_msgs:
            raise ValueError("\n".join(error_msgs))

        # ================= ç‰¹å¾åç§°éªŒè¯ =================
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¿å­˜äº†åŸå§‹ç‰¹å¾å
        model_feature_names = getattr(self.model, "feature_names_in_", None)
        if model_feature_names is not None:
            # å¯¹æ¯”ç‰¹å¾åç§°å’Œé¡ºåº
            if list(model_feature_names) != self.expected_columns:
                msg = [
                    "ç‰¹å¾åç§°æˆ–é¡ºåºä¸åŒ¹é…ï¼",
                    f"æ¨¡å‹ç‰¹å¾å: {list(model_feature_names)}",
                    f"ä»£ç é¢„æœŸ: {self.expected_columns}"
                ]
                raise ValueError("\n".join(msg))

        # ================= è™šæ‹Ÿæ•°æ®æµ‹è¯• =================
        # ç”Ÿæˆç¬¦åˆå½“å‰ä»£ç ç»´åº¦çš„éšæœºæ•°æ®
        np.random.seed(42)
        dummy_data = np.random.rand(1, code_features)
        
        try:
            dummy_scaled = self.scaler.transform(dummy_data)
            _ = self.model.predict(dummy_scaled)
        except Exception as e:
            raise RuntimeError(
                f"è™šæ‹Ÿæ•°æ®æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é¢„å¤„ç†æµç¨‹ï¼š{str(e)}"
            ) from e

    def _truncate(self, df):
        """æ—¶é—´åºåˆ—æˆªæ–­é€»è¾‘"""
        time_cols = self.time_series_cols
        row = df[time_cols].iloc[0]
        
        # å¯»æ‰¾æœ€åä¸€ä¸ªæœ‰æ•ˆç‚¹
        last_valid_idx = next(
            (idx for idx in reversed(range(len(time_cols))) if not pd.isna(row.iloc[idx])),
            None
        )
        
        # æ‰§è¡Œæˆªæ–­
        if last_valid_idx is not None and last_valid_idx < len(time_cols)-1:
            invalid_cols = time_cols[last_valid_idx+1:]
            df[invalid_cols] = np.nan
            
        return df
    def _get_slope(self, row, col=None):
        # col æ˜¯å¯é€‰çš„ï¼Œå°†è¢«å¿½ç•¥
        x = np.arange(len(row))
        y = row.values
        mask = ~np.isnan(y)
        if sum(mask) >= 2:
            return stats.linregress(x[mask], y[mask])[0]
        return np.nan

    def _calc_autocorr(self, row):
        """è®¡ç®—ä¸€é˜¶è‡ªç›¸å…³ç³»æ•°"""
        values = row.dropna().values
        if len(values) > 1:
            n = len(values)
            mean = np.mean(values)
            numerator = sum((values[:-1] - mean) * (values[1:] - mean))
            denominator = sum((values - mean) ** 2)
            if denominator != 0:
                return numerator / denominator
        return np.nan
    def _extract_time_series_features(self, df):
        # ç§»é™¤å‰å‘å¡«å……ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆåŒ…å«NaNï¼‰
        time_data = df[self.time_series_cols].copy()
        
        return pd.DataFrame({
            'seq_length': time_data.count(axis=1),  # è®¡ç®—éNaNå€¼çš„æ•°é‡
            'max_value': time_data.max(axis=1),
            'mean_value': time_data.mean(axis=1),
            'min_value': time_data.min(axis=1),
            'std_value': time_data.std(axis=1),
            'trend': time_data.apply(self._get_slope, axis=1),
            'range_value': time_data.max(axis=1) - time_data.min(axis=1),
            'autocorr': time_data.apply(self._calc_autocorr, axis=1)
        }, columns=self.eng_features)
    def predict_one(self, sample):
        if len(sample) != len(self.full_cols):
            raise ValueError(f"éœ€è¦{len(self.full_cols)}ä¸ªç‰¹å¾ï¼Œå®é™…{len(sample)}ä¸ªã€‚å®Œæ•´é¡ºåºï¼š{self.full_cols}")
        
        df = pd.DataFrame([sample], columns=self.full_cols)
        df = self._truncate(df)
        
        # å•æ¬¡åˆå¹¶å¹¶å¼ºåˆ¶åˆ—å
        static_features = df[self.static_cols]
        time_features = self._extract_time_series_features(df)
        feature_df = pd.concat([static_features.reset_index(drop=True), 
                             time_features.reset_index(drop=True)], axis=1)
        feature_df.columns = self.expected_columns
        
        # æœ€ç»ˆéªŒè¯
        if list(feature_df.columns) != self.expected_columns:
            raise ValueError(f"åˆ—åä¸åŒ¹é…ï¼\né¢„æœŸï¼š{self.expected_columns}\nå®é™…ï¼š{feature_df.columns.tolist()}")
        
        return self.model.predict(self.scaler.transform(feature_df))[0]


import streamlit as st
import pandas as pd
import numpy as np
import joblib
import base64
import random
from deap import base, creator, tools, algorithms

# è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬base64
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# é¡µé¢é…ç½®
image_path = "å›¾ç‰‡1.png"
icon_base64 = image_to_base64(image_path)
st.set_page_config(
    page_title="èšä¸™çƒ¯LOIå’ŒTSæ¨¡å‹",
    layout="wide",
    page_icon=f"data:image/png;base64,{icon_base64}"
)

# é¡µé¢æ ‡é¢˜æ ·å¼
width = 200
height = int(158 * (width / 507))
st.markdown(
    f"""
    <h1 style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{icon_base64}" style="width: {width}px; height: {height}px; margin-right: 15px;" />
        é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°
    </h1>
    """, 
    unsafe_allow_html=True
)

# ä¾§è¾¹æ ä¸»å¯¼èˆª
page = st.sidebar.selectbox(
    "ğŸ”§ ä¸»åŠŸèƒ½é€‰æ‹©",
    ["é¦–é¡µ","æ€§èƒ½é¢„æµ‹", "é…æ–¹å»ºè®®"],
    key="main_nav"
)

# å­åŠŸèƒ½é€‰æ‹©ï¼ˆä»…åœ¨é…æ–¹å»ºè®®æ—¶æ˜¾ç¤ºï¼‰
sub_page = None
if page == "é…æ–¹å»ºè®®":
    sub_page = st.sidebar.selectbox(
        "ğŸ”§ å­åŠŸèƒ½é€‰æ‹©",
        ["é…æ–¹ä¼˜åŒ–", "æ·»åŠ å‰‚æ¨è"],
        key="sub_nav"
    )

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_models():
    loi_data = joblib.load("model_and_scaler_loi.pkl")
    ts_data = joblib.load("model_and_scaler_ts1.pkl")
    return {
        "loi_model": loi_data["model"],
        "loi_scaler": loi_data["scaler"],
        "ts_model": ts_data["model"],
        "ts_scaler": ts_data["scaler"],
        "loi_features": pd.read_excel("trainrg3.xlsx").drop(columns="LOI", errors='ignore').columns.tolist(),
        "ts_features": pd.read_excel("trainrg3TS.xlsx").drop(columns="TS", errors='ignore').columns.tolist(),
    }
models = load_models()

# è·å–å•ä½
def get_unit(fraction_type):
    if fraction_type == "è´¨é‡":
        return "g"
    elif fraction_type == "è´¨é‡åˆ†æ•°":
        return "wt%"
    elif fraction_type == "ä½“ç§¯åˆ†æ•°":
        return "vol%"

# ä¿è¯PPåœ¨é¦–åˆ—
def ensure_pp_first(features):
    if "PP" in features:
        features.remove("PP")
    return ["PP"] + sorted(features)

# é¦–é¡µ
if page == "é¦–é¡µ":
    st.markdown("""
    æœ¬å¹³å°åŸºäºå…ˆè¿›çš„äººå·¥æ™ºèƒ½å’Œææ–™ç§‘å­¦æŠ€æœ¯ï¼Œè‡´åŠ›äºæä¾›èšä¸™çƒ¯ï¼ˆPPï¼‰ç­‰èšåˆç‰©å¤åˆææ–™çš„æ€§èƒ½é¢„æµ‹ä¸é…æ–¹ä¼˜åŒ–å»ºè®®ã€‚
    é€šè¿‡æœ¬å¹³å°ï¼Œç”¨æˆ·å¯ä»¥è¿›è¡Œææ–™æ€§èƒ½é¢„æµ‹ï¼ˆå¦‚LOIå’ŒTSé¢„æµ‹ï¼‰ï¼Œå¹¶æ ¹æ®æ€§èƒ½ç›®æ ‡ä¼˜åŒ–é…æ–¹ï¼Œæ¨èé€‚åˆçš„åŠ©å‰‚ã€‚
    """)
    st.markdown("<hr>", unsafe_allow_html=True)  # æ·»åŠ æ°´å¹³åˆ†éš”çº¿
    # åŠŸèƒ½æ¦‚è§ˆ
    st.markdown("""
    ## åŠŸèƒ½æ¦‚è§ˆ
    1. **æ€§èƒ½é¢„æµ‹**ï¼šé€šè¿‡è¾“å…¥ææ–™é…æ–¹ï¼Œé¢„æµ‹èšåˆç‰©å¤åˆææ–™çš„LOIå’ŒTSæ€§èƒ½ã€‚
    2. **é…æ–¹å»ºè®®**ï¼šæ ¹æ®ç›®æ ‡æ€§èƒ½ï¼Œä¼˜åŒ–ææ–™é…æ–¹ã€‚
    3. **æ·»åŠ å‰‚æ¨è**ï¼šæ ¹æ®é»„åº¦å€¼ç­‰æ—¶åºæ•°æ®ï¼Œæ™ºèƒ½æ¨èæœ€ä½³æ·»åŠ å‰‚ã€‚
    """)
    st.markdown("<hr>", unsafe_allow_html=True)  # æ·»åŠ æ°´å¹³åˆ†éš”çº¿
    # å¼•ç”¨éƒ¨åˆ†
    st.markdown("""
    ## **å¼•ç”¨**
    Weibin, Ma; Ling, Li; Yu, Zhang et al. Active learning-based generative design of halogen-free flame-retardant polymeric composites. Journal of Materials Informatics
    """)

    # è‡´è°¢éƒ¨åˆ†ä¼˜åŒ–ï¼Œæ·»åŠ æ¢è¡Œç¬¦
    st.markdown("""
    ## **è‡´è°¢**<br>
    *è´¡çŒ®è€…*ï¼š<br>
    *å›¢é˜Ÿ*ï¼š<br>
    ä¸Šæµ·å¤§å­¦åŠŸèƒ½é«˜åˆ†å­ç»„<br>
    *å¼€å‘è€…*ï¼š<br>
    é©¬ç»´å®¾åšå£«ç”Ÿ<br>
    *å®¡æŸ¥*ï¼š<br>
    ä¸é¹æ•™æˆ<br>
    *åŸºé‡‘æ”¯æŒ*ï¼š<br>
    äº‘å—çœç§‘æŠ€é‡ç‚¹è®¡åˆ’é¡¹ç›® ï¼ˆ202302AB080022ï¼‰ã€è‹å·å¸‚é‡ç‚¹æŠ€æœ¯ç ”ç©¶é¡¹ç›® ï¼ˆSYG2024017ï¼‰
    """, unsafe_allow_html=True)

    # æ·»åŠ åˆ†éš”çº¿å’ŒèƒŒæ™¯è‰²
    st.markdown("<hr>", unsafe_allow_html=True)  # æ·»åŠ æ°´å¹³åˆ†éš”çº¿


# æ€§èƒ½é¢„æµ‹é¡µé¢
elif page == "æ€§èƒ½é¢„æµ‹":
    st.subheader("ğŸ”® æ€§èƒ½é¢„æµ‹ï¼šåŸºäºé…æ–¹é¢„æµ‹LOIå’ŒTS")
    
    matrix_materials = ["PP", "PA", "PC/ABS", "POM", "PBT", "PVC", "å…¶ä»–"]
    flame_retardants = [
        "AHP", "ammonium octamolybdate", "Al(OH)3", "CFA", "APP", "Pentaerythritol", "DOPO", 
        "EPFR-1100NT", "XS-FR-8310", "ZS", "XiuCheng", "ZHS", "ZnB", "antimony oxides", 
        "Mg(OH)2", "TCA", "MPP", "PAPP", "å…¶ä»–"
    ]
    additives = [
        "wollastonite", "M-2200B", "ZBS-PV-OA", "FP-250S", "silane coupling agent", "antioxidant", 
        "SiO2", "å…¶ä»–"
    ]
    
    fraction_type = st.sidebar.selectbox("é€‰æ‹©è¾“å…¥çš„å•ä½", ["è´¨é‡", "è´¨é‡åˆ†æ•°", "ä½“ç§¯åˆ†æ•°"])

    st.subheader("è¯·é€‰æ‹©é…æ–¹ä¸­çš„åŸºä½“ã€é˜»ç‡ƒå‰‚å’ŒåŠ©å‰‚")
    selected_matrix = st.selectbox("é€‰æ‹©åŸºä½“", matrix_materials, index=0)
    selected_flame_retardants = st.multiselect("é€‰æ‹©é˜»ç‡ƒå‰‚", flame_retardants, default=["ZS"])
    selected_additives = st.multiselect("é€‰æ‹©åŠ©å‰‚", additives, default=["wollastonite"])
    
    input_values = {}
    unit_matrix = get_unit(fraction_type)
    unit_flame_retardant = get_unit(fraction_type)
    unit_additive = get_unit(fraction_type)
    
    input_values[selected_matrix] = st.number_input(f"é€‰æ‹© {selected_matrix} ({unit_matrix})", min_value=0.0, max_value=100.0, value=50.0, step=0.1)
    
    for fr in selected_flame_retardants:
        input_values[fr] = st.number_input(f"é€‰æ‹© {fr}({unit_flame_retardant})", min_value=0.0, max_value=100.0, value=10.0, step=0.1)
    
    for ad in selected_additives:
        input_values[ad] = st.number_input(f"é€‰æ‹© {ad}  ({unit_additive})", min_value=0.0, max_value=100.0, value=10.0, step=0.1)
    
    total = sum(input_values.values())
    is_only_pp = all(v == 0 for k, v in input_values.items() if k != "PP")
    
    with st.expander("âœ… è¾“å…¥éªŒè¯"):
        if fraction_type == "ä½“ç§¯åˆ†æ•°":
            if abs(total - 100.0) > 1e-6:
                st.error(f"â— ä½“ç§¯åˆ†æ•°çš„æ€»å’Œå¿…é¡»ä¸º100%ï¼ˆå½“å‰ï¼š{total:.2f}%ï¼‰")
            else:
                st.success("ä½“ç§¯åˆ†æ•°æ€»å’ŒéªŒè¯é€šè¿‡")
        elif fraction_type == "è´¨é‡åˆ†æ•°":
            if abs(total - 100.0) > 1e-6:
                st.error(f"â— è´¨é‡åˆ†æ•°çš„æ€»å’Œå¿…é¡»ä¸º100%ï¼ˆå½“å‰ï¼š{total:.2f}%ï¼‰")
            else:
                st.success("è´¨é‡åˆ†æ•°æ€»å’ŒéªŒè¯é€šè¿‡")
        else:
            st.success("æˆåˆ†æ€»å’ŒéªŒè¯é€šè¿‡")
            if is_only_pp:
                st.info("æ£€æµ‹åˆ°çº¯PPé…æ–¹")

    if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
        if fraction_type in ["ä½“ç§¯åˆ†æ•°", "è´¨é‡åˆ†æ•°"] and abs(total - 100.0) > 1e-6:
            st.error(f"é¢„æµ‹ä¸­æ­¢ï¼š{fraction_type}çš„æ€»å’Œå¿…é¡»ä¸º100%")
            st.stop()

        if is_only_pp:
            loi_pred = 17.5
            ts_pred = 35.0
        else:
            if fraction_type == "ä½“ç§¯åˆ†æ•°":
                vol_values = np.array(list(input_values.values()))
                mass_values = vol_values
                total_mass = mass_values.sum()
                input_values = {k: (v / total_mass * 100) for k, v in zip(input_values.keys(), mass_values)}
            
            for feature in models["loi_features"]:
                if feature not in input_values:
                    input_values[feature] = 0.0

            loi_input = np.array([[input_values[f] for f in models["loi_features"]]])
            loi_scaled = models["loi_scaler"].transform(loi_input)
            loi_pred = models["loi_model"].predict(loi_scaled)[0]
        
            for feature in models["ts_features"]:
                if feature not in input_values:
                    input_values[feature] = 0.0

            ts_input = np.array([[input_values[f] for f in models["ts_features"]]])
            ts_scaled = models["ts_scaler"].transform(ts_input)
            ts_pred = models["ts_model"].predict(ts_scaled)[0]
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric(label="LOIé¢„æµ‹å€¼", value=f"{loi_pred:.2f}%")
        with col2:
            st.metric(label="TSé¢„æµ‹å€¼", value=f"{ts_pred:.2f} MPa")

# é…æ–¹å»ºè®®é¡µé¢
elif page == "é…æ–¹å»ºè®®":
    if sub_page == "é…æ–¹ä¼˜åŒ–":
        fraction_type = st.sidebar.radio(
            "ğŸ“ å•ä½ç±»å‹",
            ["è´¨é‡", "è´¨é‡åˆ†æ•°", "ä½“ç§¯åˆ†æ•°"],
            key="unit_type"
        )
        st.subheader("ğŸ§ª é…æ–¹å»ºè®®ï¼šæ ¹æ®æ€§èƒ½åæ¨é…æ–¹")
    
        col1, col2 = st.columns(2)
        with col1:
            target_loi = st.number_input("ç›®æ ‡LOIå€¼ï¼ˆ%ï¼‰", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
        with col2:
            target_ts = st.number_input("ç›®æ ‡TSå€¼ï¼ˆMPaï¼‰", min_value=10.0, max_value=100.0, value=50.0, step=0.1)
        
        with st.expander("âš™ï¸ ç®—æ³•å‚æ•°è®¾ç½®"):
            pop_size = st.number_input("ç§ç¾¤æ•°é‡", 50, 500, 200)
            n_gen = st.number_input("è¿­ä»£ä»£æ•°", 10, 100, 50)
            cx_prob = st.slider("äº¤å‰æ¦‚ç‡", 0.1, 1.0, 0.7)
            mut_prob = st.slider("å˜å¼‚æ¦‚ç‡", 0.1, 1.0, 0.2)
    
        if st.button("ğŸ” å¼€å§‹ä¼˜åŒ–", type="primary"):
            creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
            creator.create("Individual", list, fitness=creator.FitnessMin)
            
            toolbox = base.Toolbox()
            all_features = ensure_pp_first(list(set(models["loi_features"] + models["ts_features"])))
            n_features = len(all_features)
            
            def generate_individual():
                individual = [random.uniform(0, 100) for _ in range(n_features)]
                total = sum(individual)
                return [max(0, x / total * 100) for x in individual]
            
            toolbox.register("individual", tools.initIterate, creator.Individual, generate_individual)
            toolbox.register("population", tools.initRepeat, list, toolbox.individual)
            
            def evaluate(individual):
                if fraction_type == "ä½“ç§¯åˆ†æ•°":
                    vol_values = np.array(individual)
                    mass_values = vol_values
                    total_mass = mass_values.sum()
                    if total_mass == 0:
                        return (1e6,)
                    mass_percent = (mass_values / total_mass) * 100
                else:
                    total = sum(individual)
                    if total == 0:
                        return (1e6,)
                    mass_percent = np.array(individual) / total * 100
                
                pp_index = all_features.index("PP")
                pp_content = mass_percent[pp_index]
                if pp_content < 50:
                    return (1e6,)
                
                loi_input = mass_percent[:len(models["loi_features"])]
                loi_scaled = models["loi_scaler"].transform([loi_input])
                loi_pred = models["loi_model"].predict(loi_scaled)[0]
                loi_error = abs(target_loi - loi_pred)
                
                ts_input = mass_percent[:len(models["ts_features"])]
                ts_scaled = models["ts_scaler"].transform([ts_input])
                ts_pred = models["ts_model"].predict(ts_scaled)[0]
                ts_error = abs(target_ts - ts_pred)
                total = sum(mass_percent)
                if abs(total - 100) > 1e-6:
                    return (1e6,)
                return (loi_error + ts_error,)
            
            toolbox.register("mate", tools.cxBlend, alpha=0.5)
            toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)
            toolbox.register("select", tools.selTournament, tournsize=3)
            toolbox.register("evaluate", evaluate)
            
            population = toolbox.population(n=pop_size)
            algorithms.eaSimple(population, toolbox, cxpb=cx_prob, mutpb=mut_prob, ngen=n_gen, verbose=False)
            
            best_individuals = tools.selBest(population, 10)
            best_values = []
            for individual in best_individuals:
                total = sum(individual)
                best_values.append([round(max(0, i / total * 100), 2) for i in individual])  # ä¿®æ­£æ‹¬å·é—­åˆ
            
            result_df = pd.DataFrame(best_values, columns=all_features)
            units = [get_unit(fraction_type) for _ in all_features]
            result_df.columns = [f"{col} ({unit})" for col, unit in zip(result_df.columns, units)]
            st.write(result_df)
    
    elif sub_page == "æ·»åŠ å‰‚æ¨è":
        st.subheader("ğŸ§ª PVCæ·»åŠ å‰‚æ™ºèƒ½æ¨è")
        try:
            predictor = Predictor("scaler_fold_1.pkl", "svc_fold_1.pkl")
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.stop()
    
        with st.form("additive_form"):
            st.subheader("ğŸ§ª PVCæ·»åŠ å‰‚æ™ºèƒ½æ¨è")
            
            # åŸºç¡€å‚æ•°
            col1, col2, col3 = st.columns(3)
            with col1: sn = st.number_input("Sn%", 0.0, 100.0, 5.0)
            with col2: ratio = st.number_input("æ·»åŠ æ¯”ä¾‹", 0.0, 100.0, 14.0)
            with col3: yijia = st.number_input("ä¸€ç”²%", 0.0, 100.0, 23.55)
            
            # æ—¶åºå‚æ•°
            st.markdown("### é»„åº¦å€¼æ—¶åºå‚æ•°")
            time_points = ["3min", "6min", "9min", "12min", "15min", "18min", "21min", "24min"]
            yellow = {}
            cols = st.columns(4)
            prev_val = 0.0
            
            for idx, t in enumerate(time_points):
                with cols[idx%4]:
                    yellow[t] = st.number_input(
                        f"{t} é»„åº¦å€¼",
                        min_value=prev_val if idx>0 else 0.0,
                        max_value=25.0,
                        value=15.0+idx,
                        key=f"yellow_{t}"
                    )
                    prev_val = yellow[t]
            
            # æäº¤æŒ‰é’®
            if st.form_submit_button("ç”Ÿæˆæ¨è"):
                try:
                    # æ„å»ºè¾“å…¥æ ·æœ¬ï¼ˆä¸¥æ ¼æŒ‰é¡ºåºï¼‰
                    sample = [sn, ratio, yijia] + [yellow[t] for t in time_points]
                    
                    # æ‰§è¡Œé¢„æµ‹
                    pred = predictor.predict_one(sample)
                    
                    # æ˜¾ç¤ºç»“æœ
                    result_map = {
                        1: "æ— æ¨èæ·»åŠ å‰‚", 2: "æ°¯åŒ–çŸ³èœ¡", 3: "EA12", 
                        4: "EA15", 5: "EA16", 6: "G70L", 7: "EA6"
                    }
                    additive = result_map.get(pred, "æœªçŸ¥")
                    
                    # æ„å»ºå±•ç¤ºæ•°æ®
                    formula = [
                        ["PVCä»½æ•°", 100.0], ["ACRä»½æ•°", 1.0], ["70Sä»½æ•°", 0.35],
                        ["MBSä»½æ•°", 5.0], ["316Aä»½æ•°", 0.2], ["ç¨³å®šå‰‚ä»½æ•°", 1.0],
                        ["ä¸€ç”²%", yijia], ["Sn%", sn]
                    ]
                    if pred != 1:
                        formula.extend([[f"{additive}å«é‡", f"{ratio if pred!=1 else 0}%"]])
    
                    # æ˜¾ç¤ºç»“æœ
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("æ¨èç»“æœ", additive)
                    with col2:
                        st.dataframe(pd.DataFrame(formula, columns=["ææ–™", "å«é‡"]), 
                                   hide_index=True)
                        
                except Exception as e:
                    st.error(f"é¢„æµ‹é”™è¯¯: {str(e)}")
# æ·»åŠ é¡µè„š
def add_footer():
    st.markdown("""
    <hr>
    <footer style="text-align: center;">
        <p>Â© 2025 é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°</p>
        <p>å¼€å‘è€…: é©¬ç»´å®¾</p>
        <p>å¹³å°æ€§è´¨å£°æ˜ï¼šæœ¬å¹³å°ä¸ºç§‘ç ”åä½œç½‘ç»œæœåŠ¡å¹³å°ï¼Œæ‰€æœ‰å†…å®¹ä»…ä¾›å­¦æœ¯ç ”ç©¶ã€æŠ€æœ¯éªŒè¯ç­‰éè¥åˆ©æ€§ç§‘ç ”æ´»åŠ¨ä½¿ç”¨ï¼Œä¸¥ç¦ç”¨äºä»»ä½•å•†ä¸šç”¨é€”ã€‚</p>
    </footer>
    """, unsafe_allow_html=True)

add_footer() 
