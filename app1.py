import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
from deap import base, creator, tools, algorithms
import random
import base64

# è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬base64
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# é¡µé¢é…ç½®
image_path = "å›¾ç‰‡1.png"
icon_base64 = image_to_base64(image_path)
st.set_page_config(
    page_title="èšä¸™çƒ¯LOIæ¨¡å‹",
    layout="wide",
    page_icon=f"data:image/png;base64,{icon_base64}"
)

# é¡µé¢æ ‡é¢˜æ ·å¼
width = 200
height = int(158 * (width / 507))
st.markdown(
    f"""
    <h1 style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{icon_base64}" style="width: {width}px; height: {height}px; margin-right: 15px;" />
        é˜»ç‡ƒèšåˆç‰©å¤åˆææ–™æ™ºèƒ½è®¾è®¡å¹³å°
    </h1>
    """, 
    unsafe_allow_html=True
)

# ä¾§è¾¹æ å¯¼èˆª
page = st.sidebar.selectbox("ğŸ”§ é€‰æ‹©åŠŸèƒ½", ["æ€§èƒ½é¢„æµ‹", "é…æ–¹å»ºè®®"])

# åŠ è½½æ¨¡å‹å’Œæ•°æ®
data = joblib.load("model_and_scaler_loi.pkl")
model = data["model"]
scaler = data["scaler"]
df = pd.read_excel("trainrg3.xlsx")
feature_names = df.columns.tolist()
if "LOI" in feature_names:
    feature_names.remove("LOI")

# å•ä½ç±»å‹å¤„ç†
unit_type = st.radio("ğŸ“ è¯·é€‰æ‹©é…æ–¹è¾“å…¥å•ä½", ["è´¨é‡ (g)", "è´¨é‡åˆ†æ•° (wt%)", "ä½“ç§¯åˆ†æ•° (vol%)"], horizontal=True)

# æ€§èƒ½é¢„æµ‹é¡µé¢
if page == "æ€§èƒ½é¢„æµ‹":
    st.subheader("ğŸ”® æ€§èƒ½é¢„æµ‹ï¼šåŸºäºé…æ–¹é¢„æµ‹LOI")
    user_input = {}

    for feature in feature_names:
        user_input[feature] = st.number_input(f"è¯·è¾“å…¥ {feature} çš„å€¼", value=0.0, step=0.1)

    # æ€§èƒ½é¢„æµ‹æŒ‰é’®
    if st.button("é¢„æµ‹LOI"):
        input_data = np.array([list(user_input.values())])
        input_scaled = scaler.transform(input_data)
        predicted_loi = model.predict(input_scaled)[0]
        st.success(f"é¢„æµ‹çš„LOIå€¼ä¸ºï¼š{predicted_loi:.2f}")
    
# é…æ–¹å»ºè®®é¡µé¢
elif page == "é…æ–¹å»ºè®®":
    st.subheader("ğŸ§ª é…æ–¹å»ºè®®ï¼šæ ¹æ®æ€§èƒ½åæ¨é…æ–¹")
    target_loi = st.number_input("ç›®æ ‡LOIå€¼", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
    
    # é—ä¼ ç®—æ³•é…ç½®
    creator.create("FitnessMin", base.Fitness, weights=(-1.0,))  
    creator.create("Individual", list, fitness=creator.FitnessMin)
    
    toolbox = base.Toolbox()
    toolbox.register("attr_float", random.uniform, 0.01, 50)
    toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, n=len(feature_names))
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)
    
    def evaluate(individual):
        # å¼ºåˆ¶PPå«é‡>=50ä¸”ä¸ºæœ€å¤§å€¼
        pp_index = feature_names.index("PP")
        if individual[pp_index] < 50:
            return (1000,)
        if individual[pp_index] != max(individual):
            return (1000,)
            
        # å½’ä¸€åŒ–å¤„ç†
        total = sum(individual)
        normalized = [x/total*100 for x in individual]
        
        # é¢„æµ‹LOI
        input_array = np.array([normalized])
        input_scaled = scaler.transform(input_array)
        predicted = model.predict(input_scaled)[0]
        
        return (abs(predicted - target_loi),)
    
    # é—ä¼ ç®—æ³•æ“ä½œé…ç½®
    toolbox.register("mate", tools.cxBlend, alpha=0.5)
    toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=5, indpb=0.2)
    toolbox.register("select", tools.selTournament, tournsize=3)
    toolbox.register("evaluate", evaluate)
    
    if st.button("ç”Ÿæˆæ¨èé…æ–¹"):
        with st.spinner("ğŸ” æ­£åœ¨ä¼˜åŒ–é…æ–¹..."):
            # ç®—æ³•å‚æ•°
            POP_SIZE = 200  # å¢å¤§ç§ç¾¤è§„æ¨¡
            GEN_NUM = 100   # å¢åŠ è¿›åŒ–ä»£æ•°
            CXPB = 0.7
            MUTPB = 0.3
            
            pop = toolbox.population(n=POP_SIZE)
            hof = tools.HallOfFame(10)  # ä¿å­˜å‰10ä¸ªæœ€ä½³ä¸ªä½“
            stats = tools.Statistics(lambda ind: ind.fitness.values)
            stats.register("avg", np.mean)
            stats.register("min", np.min)
            
            # è¿›åŒ–å¾ªç¯
            algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=GEN_NUM, 
                              stats=stats, halloffame=hof, verbose=False)
            
            # æ”¶é›†æœ‰æ•ˆé…æ–¹ï¼Œç¡®ä¿å¤šæ ·æ€§
            valid_recipes = []
            unique_recipes = set()  # ç”¨äºç¡®ä¿é…æ–¹ä¸åŒ
            
            for ind in hof:
                if ind.fitness.values[0] < 1000:  # è¿‡æ»¤æœ‰æ•ˆè§£
                    total = sum(ind)
                    recipe = {name: (val/total)*100 for name, val in zip(feature_names, ind)}
                    
                    # ç”Ÿæˆé…æ–¹å”¯ä¸€æ ‡è¯†
                    recipe_tuple = tuple(recipe.items())
                    if recipe_tuple not in unique_recipes:
                        unique_recipes.add(recipe_tuple)
                        valid_recipes.append(recipe)
                if len(valid_recipes) >= 10:
                    break
            
            if not valid_recipes:
                st.error("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆé…æ–¹ï¼Œè¯·è°ƒæ•´ç›®æ ‡å€¼æˆ–å‚æ•°")
            else:
                st.success(f"âœ… æ‰¾åˆ° {len(valid_recipes)} ä¸ªæœ‰æ•ˆé…æ–¹ï¼")
                
                # ç”Ÿæˆç»“æœè¡¨æ ¼
                recipe_df = pd.DataFrame(valid_recipes)
                recipe_df.index = [f"é…æ–¹ {i+1}" for i in range(len(recipe_df))]
                
                # æ ¹æ®å•ä½ç±»å‹è°ƒæ•´æ˜¾ç¤º
                unit_label = {
                    "è´¨é‡ (g)": "g",
                    "è´¨é‡åˆ†æ•° (wt%)": "wt%",
                    "ä½“ç§¯åˆ†æ•° (vol%)": "vol%"
                }[unit_type]
                
                # å•ä½è½¬æ¢å¤„ç†ï¼šç›´æ¥ä½¿ç”¨è´¨é‡åˆ†æ•°ä½œä¸ºä½“ç§¯åˆ†æ•°
                if unit_type == "ä½“ç§¯åˆ†æ•° (vol%)":
                    # ä½“ç§¯åˆ†æ•°å³ä¸ºè´¨é‡åˆ†æ•°çš„æ¯”ä¾‹
                    for name in feature_names:
                        recipe_df[name] = recipe_df[name]  # ä½“ç§¯åˆ†æ•°ç­‰äºè´¨é‡åˆ†æ•°
                
                recipe_df.columns = [f"{name} ({unit_label})" for name in feature_names]
                
                st.dataframe(recipe_df)
