import streamlit as st
import random
import numpy as np
import pandas as pd
from deap import base, creator, tools, algorithms
import joblib
from sklearn.preprocessing import StandardScaler

# å‡è®¾æ‚¨çš„æ¨¡å‹æ–‡ä»¶å­˜åœ¨ä»¥ä¸‹è·¯å¾„
scaler_path = "models/scaler_fold_1.pkl"
svc_path = "models/svc_fold_1.pkl"
loi_model_path = "models/loi_model.pkl"
ts_model_path = "models/ts_model.pkl"
loi_scaler_path = "models/loi_scaler.pkl"
ts_scaler_path = "models/ts_scaler.pkl"

# è½½å…¥æ¨¡å‹
class Predictor:
    def __init__(self, scaler_path, svc_path):
        self.scaler = joblib.load(scaler_path)
        self.svc = joblib.load(svc_path)

    def predict_one(self, features):
        features_scaled = self.scaler.transform([features])
        prediction = self.svc.predict(features_scaled)
        return prediction[0]

# è½½å…¥é…æ–¹æ¨¡å‹
models = {
    "loi_model": joblib.load(loi_model_path),
    "ts_model": joblib.load(ts_model_path),
    "loi_scaler": joblib.load(loi_scaler_path),
    "ts_scaler": joblib.load(ts_scaler_path),
    "loi_features": ["feature1", "feature2", "feature3"],  # ä¿®æ”¹ä¸ºå®é™…çš„ç‰¹å¾
    "ts_features": ["feature1", "feature2", "feature3"]  # ä¿®æ”¹ä¸ºå®é™…çš„ç‰¹å¾
}

def ensure_pp_first(features):
    if "PP" in features:
        features.remove("PP")
        features.insert(0, "PP")
    return features

def get_unit(fraction_type):
    return "ä½“ç§¯åˆ†æ•°" if fraction_type == "ä½“ç§¯åˆ†æ•°" else "è´¨é‡ç™¾åˆ†æ¯”"

# åˆå§‹åŒ–é—ä¼ ç®—æ³•
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)

toolbox = base.Toolbox()
all_features = ensure_pp_first(list(set(models["loi_features"] + models["ts_features"])))
n_features = len(all_features)

# ç”Ÿæˆæ»¡è¶³å’Œä¸º100çš„é…æ–¹
def generate_individual():
    individual = [random.uniform(0, 100) for _ in range(n_features)]
    total = sum(individual)
    return [max(0, x / total * 100) for x in individual]

toolbox.register("individual", tools.initIterate, creator.Individual, generate_individual)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

def evaluate(individual):
    if fraction_type == "ä½“ç§¯åˆ†æ•°":
        vol_values = np.array(individual)
        mass_values = vol_values
        total_mass = mass_values.sum()
        mass_percent = (mass_values / total_mass) * 100
    else:
        total = sum(individual)
        mass_percent = np.array(individual) / total * 100

    pp_index = all_features.index("PP")
    pp_content = mass_percent[pp_index]
    if pp_content < 50:
        return (1e6,)

    loi_input = mass_percent[:len(models["loi_features"])]
    loi_scaled = models["loi_scaler"].transform([loi_input])
    loi_pred = models["loi_model"].predict(loi_scaled)[0]
    loi_error = abs(target_loi - loi_pred)

    ts_input = mass_percent[:len(models["ts_features"])]
    ts_scaled = models["ts_scaler"].transform([ts_input])
    ts_pred = models["ts_model"].predict(ts_scaled)[0]
    ts_error = abs(target_ts - ts_pred)

    return (loi_error + ts_error,)

toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)
toolbox.register("evaluate", evaluate)

# é¡µé¢ç»“æ„
st.title("é…æ–¹ä¼˜åŒ–ç³»ç»Ÿ")

# é¡µé¢é€‰æ‹©
sub_page = st.radio("è¯·é€‰æ‹©æ“ä½œ", ("é…æ–¹ä¼˜åŒ–", "æ·»åŠ å‰‚æ¨è"))

if sub_page == "é…æ–¹ä¼˜åŒ–":
    st.subheader("ğŸ§ª é…æ–¹å»ºè®®ï¼šæ ¹æ®æ€§èƒ½åæ¨é…æ–¹")

    # ç›®æ ‡è¾“å…¥
    col1, col2 = st.columns(2)
    with col1:
        target_loi = st.number_input("ç›®æ ‡LOIå€¼ï¼ˆ%ï¼‰", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
    with col2:
        target_ts = st.number_input("ç›®æ ‡TSå€¼ï¼ˆMPaï¼‰", min_value=0.0, max_value=100.0, value=50.0, step=0.1)

    # é—ä¼ ç®—æ³•å‚æ•°
    with st.expander("âš™ï¸ ç®—æ³•å‚æ•°è®¾ç½®"):
        pop_size = st.number_input("ç§ç¾¤æ•°é‡", 50, 500, 200)
        n_gen = st.number_input("è¿­ä»£ä»£æ•°", 10, 100, 50)
        cx_prob = st.slider("äº¤å‰æ¦‚ç‡", 0.1, 1.0, 0.7)
        mut_prob = st.slider("å˜å¼‚æ¦‚ç‡", 0.1, 1.0, 0.2)

    if st.button("ğŸ” å¼€å§‹ä¼˜åŒ–", type="primary"):
        population = toolbox.population(n=pop_size)
        algorithms.eaSimple(population, toolbox, cxpb=cx_prob, mutpb=mut_prob, ngen=n_gen, verbose=False)

        best_individuals = tools.selBest(population, 10)
        best_values = []
        for individual in best_individuals:
            total = sum(individual)
            best_values.append([round(max(0, i / total * 100), 2) for i in individual])

        result_df = pd.DataFrame(best_values, columns=all_features)
        units = [get_unit("ä½“ç§¯åˆ†æ•°") for _ in all_features]
        result_df.columns = [f"{col} ({unit})" for col, unit in zip(result_df.columns, units)]

        st.write(result_df)

elif sub_page == "æ·»åŠ å‰‚æ¨è":
    st.subheader("æ ¹æ®è¾“å…¥æ€§èƒ½æ¨èæ·»åŠ å‰‚é…æ–¹")
    predictor = Predictor(scaler_path, svc_path)
    
    # è·å–è¾“å…¥ç‰¹å¾
    features = st.text_input("è¾“å…¥ç‰¹å¾å€¼ï¼Œæ ¼å¼ï¼š[feature1, feature2, feature3]")

    if st.button("ğŸ” å¼€å§‹é¢„æµ‹"):
        if features:
            features = eval(features)  # å°†è¾“å…¥çš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
            prediction = predictor.predict_one(features)
            st.write(f"æ¨èçš„æ·»åŠ å‰‚é…æ–¹ä¸ºï¼š{prediction}")
